"use strict";(self.webpackChunkjue_jin_book_press=self.webpackChunkjue_jin_book_press||[]).push([["18540"],{670439:function(n,e,a){a.r(e),a.d(e,{default:()=>m});var r=a(552676),s=a(740453);let i=a.p+"static/image/e33dc608c04abcc309d5187e4a573946.746eba74.webp",l=a.p+"static/image/d2cd943e32992a929f97ba6ed26e1093.99a9ad7a.webp",c=a.p+"static/image/78215203fd5affe3d215cfb5dd21151e.138a9dfb.webp",d=a.p+"static/image/43f9e10781fcbd2e60604e97124d84de.441ec824.webp",h=a.p+"static/image/07629c477e132189f79d23ddad6f0266.cdbe1446.webp",p=a.p+"static/image/806b586eb0c428c1d5803afdb021428f.1dabfe11.webp",t=a.p+"static/image/8cdad922023dc11cab19d1beaa2b1198.e0a62335.webp",o=a.p+"static/image/597b9f9ddbdf3fe4fd2713ac31ef0b66.ba919013.webp",j=a.p+"static/image/d2a2ec04666dacffcd286a8b1beba838.2302d266.webp";function x(n){let e=Object.assign({h1:"h1",a:"a",p:"p",h2:"h2",img:"img",br:"br",ul:"ul",li:"li",code:"code",strong:"strong",pre:"pre"},(0,s.ah)(),n.components);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(e.h1,{id:"3-如何方便地获取-openai-服务",children:["3-如何方便地获取 OpenAI 服务？",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#3-如何方便地获取-openai-服务",children:"#"})]}),"\n",(0,r.jsx)(e.p,{children:"我们这一节介绍如何最方便的获得 OpenAI 的服务，其中会介绍除 OpenAI 官方 API 外几种常见获取 llm 服务的方式，以及如何在 langchain 中使用。"}),"\n",(0,r.jsx)(e.p,{children:"如果你能获得稳定的官方 API，那可以跳过本章的大部分内容。"}),"\n",(0,r.jsxs)(e.h2,{id:"azure-openai",children:["Azure OpenAI",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#azure-openai",children:"#"})]}),"\n",(0,r.jsx)(e.p,{children:"Azure OpenAI 的优势是跟 OpenAI 同源，并且国内付款比较容易。"}),"\n",(0,r.jsxs)(e.p,{children:["正常注册 microsoft 账号，并注册登录 azure ",(0,r.jsx)(e.a,{href:"https://azure.microsoft.com/en-us/",target:"_blank",rel:"noopener noreferrer",children:"link"}),"。这里注册 azure 的时候，需要手机号验证码，国内正常 +86 手机即可。还需要一张信用卡，在不开启付费业务的情况下不会有支出。"]}),"\n",(0,r.jsx)(e.p,{children:"我为了这个教程新注册了一个 azure 账号，会送 200 刀的的额度帮助大家上手，这个额度是有期限的。具体大家注册时候的活动不确定，但看起来是个长期的活动。"}),"\n",(0,r.jsx)(e.p,{children:"进入 azure 首页后，搜索 OpenAI："}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:j,alt:"CleanShot 2024-04-23 at 22.11.05@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:"然后我们创建一个 Azure OpenAI 的服务："}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:o,alt:"CleanShot 2024-04-23 at 22.12.10@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:"目前 OpenAI 的业务需要申请才能使用，第一次打开这个界面会提醒填写表单进行申请："}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:t,alt:"CleanShot 2024-04-23 at 22.13.36@2x.png"})}),"\n",(0,r.jsxs)(e.p,{children:["按照表单内容填写公司相关的信息即可，邮箱一定使用公司的邮箱，使用个人邮箱会被直接拒绝，一般需要等待几天即可。",(0,r.jsx)(e.br,{}),"\n","我们假设大家已经通过申请。"]}),"\n",(0,r.jsx)(e.p,{children:"第一个 tab 基本信息，就按照其说明正常填写，这里需要注意两个点："}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"名称。这也会成为之后我们 openai 服务的 endpoint 的前缀"}),"\n",(0,r.jsx)(e.li,{children:"区域。因为每个区域的 GPU 数量是不一样的，所以提供的模型和算力限制都不一样，再考虑上延迟，一般选择日本区域比较好。一个账号可以在多个区域有服务，所以如果日本的 GPU 资源紧张，可以试试加拿大/澳大利亚等区域。每个区域新模型上线的节奏也不同，比如最新的 Vision 版本可能只有部分区域有，大家可以根据需要查询官方文档。"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"网络和 Tags 这两个 Tab 大家按需填写就行，一版不用做修改，然后创建资源即可。"}),"\n",(0,r.jsx)(e.p,{children:"等待部署完成后，打开部署的服务，左上角打码部分就是你部署的名称，然后我们点击 模型部署 => 管理部署，跳转到 Azure OpenAI Studio 去管理模型。"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:p,alt:"CleanShot 2024-04-23 at 22.24.17@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:"Azure OpenAI 与 OpenAI API 有些不同，在 Azure 中，你需要先创建一个模型的部署，然后才能在 API 中使用部署名称去调用对应的部署，我们先创建一个 gpt4 的模型："}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:h,alt:"CleanShot 2024-04-23 at 22.27.06@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:d,alt:"CleanShot 2024-04-23 at 22.27.50@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:"这里模型的版本根据你服务部署所在的区域有关，并且不同模型的 API 定价不同，你可以根据需要去创建特定的模型版本。"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:c,alt:"CleanShot 2024-04-23 at 22.28.00@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:"创建之后，你就可以在聊天界面去测试这个部署："}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:l,alt:"CleanShot 2024-04-23 at 22.30.10@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:"这个界面已提供了非常丰富的参数和 prompt 功能，可以直接用来调试模型的参数和 prompt。"}),"\n",(0,r.jsxs)(e.p,{children:["然后，我们看如何在 langchain 中通过设置环境变量使用 azure openAI，首先创建一个 ",(0,r.jsx)(e.code,{children:".env"})," 文件，",(0,r.jsx)(e.strong,{children:"注意，一定要把 .env 文件加到 .gitignore 中，一定不能将此文件上传至任何公开平台"}),"。"]}),"\n",(0,r.jsx)(e.p,{children:"然后，设置其中的几个属性："}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-env",children:"AZURE_OPENAI_API_KEY=abc\nAZURE_OPENAI_API_VERSION=abc\nAZURE_OPENAI_API_DEPLOYMENT_NAME=abc\nAZURE_OPENAI_API_INSTANCE_NAME=abc\nAZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME=abc\n"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"AZURE_OPENAI_API_KEY 是你部署的服务的 Key，可以在下图中的 密钥和终结点中找到。"}),"\n",(0,r.jsxs)(e.li,{children:["AZURE_OPENAI_API_VERSION 是使用的 API 版本，目前最新的稳定版是 ",(0,r.jsx)(e.code,{children:"2024-02-01"}),"，本小册大多使用的是 ",(0,r.jsx)(e.code,{children:"2023-07-01-preview"}),"，建议学习小册时可以继续使用 ",(0,r.jsx)(e.code,{children:"2023-07-01-preview"}),"。"]}),"\n",(0,r.jsx)(e.li,{children:"AZURE_OPENAI_API_DEPLOYMENT_NAME 是你部署的模型实例的名称，我们上面刚创建了一个 gpt4 的实例叫做 gpt-4。"}),"\n",(0,r.jsx)(e.li,{children:"AZURE_OPENAI_API_INSTANCE_NAME 是你部署服务的名称，也就是下面截图左上角打码部分的名称。"}),"\n",(0,r.jsx)(e.li,{children:"AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME 是你用于 embedding 的模型实例名称。创建步骤跟创建 gpt4 模型的部署一致。"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:i,alt:"CleanShot 2024-04-24 at 16.53.36@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:"把这些环境变量设置好后，langchain 运行时会自动读取，所以我们创建 OpenAI 的服务时就可以直接："}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import { ChatOpenAI } from "@langchain/openai";\nimport { OpenAIEmbeddings } from "@langchain/openai";\n\nconst chatModel = new ChatOpenAI();\nconst embeddings = new OpenAIEmbeddings()\n'})}),"\n",(0,r.jsxs)(e.h2,{id:"第三方-openai-服务",children:["第三方 OpenAI 服务",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#第三方-openai-服务",children:"#"})]}),"\n",(0,r.jsx)(e.p,{children:"另一种，就是经过中转的第三方 OpenAI 服务，这类平台比较多，我们不做推荐，只讲解一下如何在 langchain 中使用。"}),"\n",(0,r.jsxs)(e.p,{children:["首先是在 ",(0,r.jsx)(e.code,{children:".env"})," 声明 key："]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:"OPENAI_API_KEY=abc\n"})}),"\n",(0,r.jsx)(e.p,{children:"然后在创建 ChatOpenAI 时，指定 baseUrl："}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import { ChatOpenAI } from "@langchain/openai";\nimport { HumanMessage } from "@langchain/core/messages";\n\n\nconst chatModel = new ChatOpenAI({\n    configuration: {\n        baseURL: "xxx",\n    }\n});\n\nawait chatModel.invoke([\n    new HumanMessage("Tell me a joke")\n])\n'})}),"\n",(0,r.jsxs)(e.h2,{id:"本地大模型",children:["本地大模型",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#本地大模型",children:"#"})]}),"\n",(0,r.jsx)(e.p,{children:"如果你是 win 平台，显卡显存大于 6G，mac 平台 M 系芯片 + 16G 内存基本就足够运行 7B 大小的模型。虽然推理速度较慢，但可以应付一些本地的测试。"}),"\n",(0,r.jsxs)(e.p,{children:["在 mac 平台下，我推荐用 ",(0,r.jsx)(e.a,{href:"https://ollama.com/",target:"_blank",rel:"noopener noreferrer",children:"ollma"}),"，使用起来非常简单，下载好模型后，点开这个 app 后，就会自动在 ",(0,r.jsx)(e.a,{href:"http://localhost:11434",target:"_blank",rel:"noopener noreferrer",children:"http://localhost:11434"})," host 一个 llm 的服务。",(0,r.jsx)(e.br,{}),"\n","如果是 win 平台，可以尝试一下 ",(0,r.jsx)(e.a,{href:"https://lmstudio.ai/",target:"_blank",rel:"noopener noreferrer",children:"LM Studio"}),"，其提供的模型更多，可玩性也更强一些。"]}),"\n",(0,r.jsxs)(e.p,{children:["目前我本地使用的还是 llama2，最新的已经到了 llama3，大家可以在这 ",(0,r.jsx)(e.a,{href:"https://github.com/ollama/ollama",target:"_blank",rel:"noopener noreferrer",children:"github"})," 找到目前支持的模型，llama 和 Mistral 家族的模型效果都很棒。"]}),"\n",(0,r.jsx)(e.p,{children:"然后，我们就可以在 langchian 中使用这些本地模型："}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import { Ollama } from "@langchain/community/llms/ollama";\n\nconst ollama = new Ollama({\n  baseUrl: "http://localhost:11434", \n  model: "llama2", \n});\n\n\nconst res = await ollama.invoke("讲个笑话")\n'})}),"\n",(0,r.jsx)(e.p,{children:"如果你使用的是 deno，需要在 deno.json 中加入这一行依赖别名："}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-json",children:'{\n    "imports":{\n        ...\n        "@langchain/community/": "npm:/@langchain/community/",\n        ...\n  \n    }\n}\n'})}),"\n",(0,r.jsx)(e.p,{children:"大家可以直接用 ollama 来代替小册中出现的 llm 模型，当然其效果肯定不如 gpt3.5 和 gpt4 强。但如果你不容易获得 openAI 的 API，使用本地模型进行学习和测试，也是一个省钱和方便的方案。"}),"\n",(0,r.jsxs)(e.h2,{id:"加载环境变量",children:["加载环境变量",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#加载环境变量",children:"#"})]}),"\n",(0,r.jsxs)(e.p,{children:["首先是在 nodejs 中，我们使用 ",(0,r.jsx)(e.code,{children:"dotenv/config"})," 这个第三方库："]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"yarn add dotenv/config\n"})}),"\n",(0,r.jsx)(e.p,{children:"然后，在需要使用环境变量的 js 文件中："}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import "dotenv/config";\n'})}),"\n",(0,r.jsxs)(e.p,{children:["即可，",(0,r.jsx)(e.code,{children:".env"})," 中的环境变量就会被注入到 ",(0,r.jsx)(e.code,{children:"process.env"})," 中。"]}),"\n",(0,r.jsxs)(e.p,{children:["在 Deno 中稍有不同，因为 langchain 是为 nodejs 设计，所以读取环境变量时会默认从 ",(0,r.jsx)(e.code,{children:"process.env"})," 中进行读取，所以我一般会这样 hack 一下："]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import { load } from "https://deno.land/std@0.223.0/dotenv/mod.ts";\nconst env = await load();\n\nconst process = {\n    env\n}\n'})}),"\n",(0,r.jsxs)(e.p,{children:["即，从 .env 文件加载出来所有的环境变量后，再自己创建一个全局的 ",(0,r.jsx)(e.code,{children:"process.env"})," 方便 langchain 进行读取。"]}),"\n",(0,r.jsxs)(e.h2,{id:"小结",children:["小结",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#小结",children:"#"})]}),"\n",(0,r.jsx)(e.p,{children:"本节介绍了如果没办法使用 OpenAI 官方的 API 有哪些合适的方式去获取 OpneAI 的服务，并在 Langchain 中使用。"}),"\n",(0,r.jsx)(e.p,{children:"一般是推荐大家尝试 Azure OpenAI，其定价和模型跟 OpenAI 一致，且方便国内用户付款，缺点可能是需要进行申请才能使用。 在本地进行简单测试，或者简单任务可以使用 llama3，其效果已经非常不错了。 如果要是用第三方提供的 OpenAI API 服务，就需要注意价格和风险。"}),"\n",(0,r.jsx)(e.p,{children:"然后，再次强调，一定保护好自己的 token 和 .env 文件，不能上传到任何公开渠道！"})]})}function A(){let n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:e}=Object.assign({},(0,s.ah)(),n.components);return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(x,{...n})}):x(n)}let m=A;A.__RSPRESS_PAGE_META={},A.__RSPRESS_PAGE_META["%E4%BB%8E%E5%89%8D%E7%AB%AF%E5%88%B0%20AI%EF%BC%9ALangChain.js%20%E5%85%A5%E9%97%A8%E5%92%8C%E5%AE%9E%E6%88%98_online%2F3-%E5%A6%82%E4%BD%95%E6%96%B9%E4%BE%BF%E5%9C%B0%E8%8E%B7%E5%8F%96%20OpenAI%20%E6%9C%8D%E5%8A%A1%EF%BC%9F.md"]={toc:[{text:"Azure OpenAI",id:"azure-openai",depth:2},{text:"第三方 OpenAI 服务",id:"第三方-openai-服务",depth:2},{text:"本地大模型",id:"本地大模型",depth:2},{text:"加载环境变量",id:"加载环境变量",depth:2},{text:"小结",id:"小结",depth:2}],title:"3-如何方便地获取 OpenAI 服务？",headingTitle:"3-如何方便地获取 OpenAI 服务？",frontmatter:{}}}}]);