"use strict";(self.webpackChunkjue_jin_book_press=self.webpackChunkjue_jin_book_press||[]).push([["84119"],{663488:function(e,n,h){h.r(n),h.d(n,{default:()=>i});var s=h(552676),t=h(740453);function d(e){let n=Object.assign({h1:"h1",a:"a",p:"p",pre:"pre",code:"code",h2:"h2",img:"img",ol:"ol",li:"li"},(0,t.ah)(),e.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.h1,{id:"34源码-2循序渐进--探索字典内部",children:["34源码 2：循序渐进 —— 探索「字典」内部",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#34源码-2循序渐进--探索字典内部",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"dict 是 Redis 服务器中出现最为频繁的复合型数据结构，除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典，还有带过期时间的 key 集合也是一个字典。zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"struct RedisDb {\n    dict* dict; // all keys  key=>value\n    dict* expires; // all expired keys key=>long(timestamp)\n    ...\n}\n\nstruct zset {\n    dict *dict; // all values  value=>score\n    zskiplist *zsl;\n}\n"})}),"\n",(0,s.jsxs)(n.h2,{id:"dict-内部结构",children:["dict 内部结构",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#dict-内部结构",children:"#"})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{src:"https://user-gold-cdn.xitu.io/2018/7/28/164dc873b2a899a8?w=1566&h=430&f=png&s=54972",alt:""}),"\ndict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"struct dict {\n    ...\n    dictht ht[2];\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://user-gold-cdn.xitu.io/2018/7/28/164dcaac6cec3483?w=1244&h=644&f=png&s=74678",alt:""})}),"\n",(0,s.jsx)(n.p,{children:"所以，字典数据结构的精华就落在了 hashtable 结构上了。hashtable 的结构和 Java 的 HashMap 几乎是一样的，都是通过分桶的方式解决 hash 冲突。第一维是数组，第二维是链表。数组中存储的是第二维链表的第一个元素的指针。"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"struct dictEntry {\n    void* key;\n    void* val;\n    dictEntry* next; // 链接下一个 entry\n}\nstruct dictht {\n    dictEntry** table; // 二维\n    long size; // 第一维数组的长度\n    long used; // hash 表中的元素个数\n    ...\n}\n"})}),"\n",(0,s.jsxs)(n.h2,{id:"渐进式rehash",children:["渐进式rehash",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#渐进式rehash",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的Redis表示很难承受这样耗时的过程。步子迈大了会扯着蛋，所以Redis使用渐进式rehash小步搬迁。虽然慢一点，但是肯定可以搬完。"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)\n{\n    long index;\n    dictEntry *entry;\n    dictht *ht;\n\n    // 这里进行小步搬迁\n    if (dictIsRehashing(d)) _dictRehashStep(d);\n\n    /* Get the index of the new element, or -1 if\n     * the element already exists. */\n    if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1)\n        return NULL;\n\n    /* Allocate the memory and store the new entry.\n     * Insert the element in top, with the assumption that in a database\n     * system it is more likely that recently added entries are accessed\n     * more frequently. */\n    // 如果字典处于搬迁过程中，要将新的元素挂接到新的数组下面\n    ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0];\n    entry = zmalloc(sizeof(*entry));\n    entry->next = ht->table[index];\n    ht->table[index] = entry;\n    ht->used++;\n\n    /* Set the hash entry fields. */\n    dictSetKey(d, entry, key);\n    return entry;\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"搬迁操作埋伏在当前字典的后续指令中(来自客户端的hset/hdel指令等)，但是有可能客户端闲下来了，没有了后续指令来触发这个搬迁，那么Redis就置之不理了么？当然不会，优雅的Redis怎么可能设计的这样潦草。Redis还会在定时任务中对字典进行主动搬迁。"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"// 服务器定时任务\nvoid databaseCron() {\n    ...\n    if (server.activerehashing) {\n        for (j = 0; j < dbs_per_call; j++) {\n            int work_done = incrementallyRehash(rehash_db);\n            if (work_done) {\n                /* If the function did some work, stop here, we'll do\n                 * more at the next cron loop. */\n                break;\n            } else {\n                /* If this db didn't need rehash, we'll try the next one. */\n                rehash_db++;\n                rehash_db %= server.dbnum;\n            }\n        }\n    }\n}\n"})}),"\n",(0,s.jsxs)(n.h2,{id:"查找过程",children:["查找过程",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#查找过程",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"插入和删除操作都依赖于查找，先必须把元素找到，才可以进行数据结构的修改操作。hashtable 的元素是在第二维的链表上，所以首先我们得想办法定位出元素在哪个链表上。"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-js",children:"func get(key) {\n    let index = hash_func(key) % size;\n    let entry = table[index];\n    while(entry != NULL) {\n        if entry.key == target {\n            return entry.value;\n        }\n        entry = entry.next;\n    }\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["值得注意的是代码中的",(0,s.jsx)(n.code,{children:"hash_func"}),"，它会将 key 映射为一个整数，不同的 key 会被映射成分布比较均匀散乱的整数。只有 hash 值均匀了，整个 hashtable 才是平衡的，所有的二维链表的长度就不会差距很远，查找算法的性能也就比较稳定。"]}),"\n",(0,s.jsxs)(n.h2,{id:"hash-函数",children:["hash 函数",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#hash-函数",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"hashtable 的性能好不好完全取决于 hash 函数的质量。hash 函数如果可以将 key 打散的比较均匀，那么这个 hash 函数就是个好函数。Redis 的字典默认的 hash 函数是 siphash。siphash 算法即使在输入 key 很小的情况下，也可以产生随机性特别好的输出，而且它的性能也非常突出。对于 Redis 这样的单线程来说，字典数据结构如此普遍，字典操作也会非常频繁，hash 函数自然也是越快越好。"}),"\n",(0,s.jsxs)(n.h2,{id:"hash-攻击",children:["hash 攻击",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#hash-攻击",children:"#"})]}),"\n",(0,s.jsxs)(n.p,{children:["如果 hash 函数存在偏向性，黑客就可能利用这种偏向性对服务器进行攻击。存在偏向性的 hash 函数在特定模式下的输入会导致 hash 第二维链表长度极为不均匀，甚至所有的元素都集中到个别链表中，直接导致查找效率急剧下降，从",(0,s.jsx)(n.code,{children:"O(1)"}),"退化到",(0,s.jsx)(n.code,{children:"O(n)"}),"。有限的服务器计算能力将会被 hashtable 的查找效率彻底拖垮。这就是所谓 hash 攻击。"]}),"\n",(0,s.jsxs)(n.h2,{id:"扩容条件",children:["扩容条件",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#扩容条件",children:"#"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:'/* Expand the hash table if needed */\nstatic int _dictExpandIfNeeded(dict *d)\n{\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n\n    /* If the hash table is empty expand it to the initial size. */\n    if (d->ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE);\n\n    /* If we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the "safe" threshold, we resize doubling\n     * the number of buckets. */\n    if (d->ht[0].used >= d->ht[0].size &&\n        (dict_can_resize ||\n         d->ht[0].used/d->ht[0].size > dict_force_resize_ratio))\n    {\n        return dictExpand(d, d->ht[0].used*2);\n    }\n    return DICT_OK;\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["正常情况下，当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (",(0,s.jsx)(n.code,{children:"dict_can_resize"}),")，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (",(0,s.jsx)(n.code,{children:"dict_force_resize_ratio"}),")，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。"]}),"\n",(0,s.jsxs)(n.h2,{id:"缩容条件",children:["缩容条件",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#缩容条件",children:"#"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"int htNeedsResize(dict *dict) {\n    long long size, used;\n\n    size = dictSlots(dict);\n    used = dictSize(dict);\n    return (size > DICT_HT_INITIAL_SIZE &&\n            (used*100/size < HASHTABLE_MIN_FILL));\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"当 hash 表因为元素的逐渐删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。缩容的条件是元素个数低于数组长度的 10%。缩容不会考虑 Redis 是否正在做 bgsave。"}),"\n",(0,s.jsxs)(n.h2,{id:"set-的结构",children:["set 的结构",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#set-的结构",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"Redis 里面 set 的结构底层实现也是字典，只不过所有的 value 都是 NULL，其它的特性和字典一模一样。"}),"\n",(0,s.jsxs)(n.h2,{id:"思考",children:["思考",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#思考",children:"#"})]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"为什么缩容不用考虑 bgsave？"}),"\n",(0,s.jsx)(n.li,{children:"Java 语言和 Python 语言内置的 set 容器是如何实现的？"}),"\n"]})]})}function a(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,t.ah)(),e.components);return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}let i=a;a.__RSPRESS_PAGE_META={},a.__RSPRESS_PAGE_META["Redis%20%E6%B7%B1%E5%BA%A6%E5%8E%86%E9%99%A9%EF%BC%9A%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%2F34%E6%BA%90%E7%A0%81%202%EF%BC%9A%E5%BE%AA%E5%BA%8F%E6%B8%90%E8%BF%9B%20%E2%80%94%E2%80%94%20%E6%8E%A2%E7%B4%A2%E3%80%8C%E5%AD%97%E5%85%B8%E3%80%8D%E5%86%85%E9%83%A8.md"]={toc:[{text:"dict 内部结构",id:"dict-内部结构",depth:2},{text:"渐进式rehash",id:"渐进式rehash",depth:2},{text:"查找过程",id:"查找过程",depth:2},{text:"hash 函数",id:"hash-函数",depth:2},{text:"hash 攻击",id:"hash-攻击",depth:2},{text:"扩容条件",id:"扩容条件",depth:2},{text:"缩容条件",id:"缩容条件",depth:2},{text:"set 的结构",id:"set-的结构",depth:2},{text:"思考",id:"思考",depth:2}],title:"34源码 2：循序渐进 —— 探索「字典」内部",headingTitle:"34源码 2：循序渐进 —— 探索「字典」内部",frontmatter:{}}}}]);