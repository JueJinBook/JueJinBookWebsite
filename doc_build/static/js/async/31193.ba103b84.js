"use strict";(self.webpackChunkjue_jin_book_press=self.webpackChunkjue_jin_book_press||[]).push([["31193"],{697789:function(e,n,s){s.r(n),s.d(n,{default:()=>a});var l=s(552676),r=s(740453);function i(e){let n=Object.assign({h1:"h1",a:"a",p:"p",code:"code",strong:"strong",h2:"h2",pre:"pre",img:"img",ul:"ul",li:"li",ol:"ol"},(0,r.ah)(),e.components);return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsxs)(n.h1,{id:"26拓展-5优胜劣汰--lru",children:["26拓展 5：优胜劣汰 —— LRU",(0,l.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#26拓展-5优胜劣汰--lru",children:"#"})]}),"\n",(0,l.jsx)(n.p,{children:"当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)。交换会让 Redis 的性能急剧下降，对于访问量比较频繁的 Redis 来说，这样龟速的存取效率基本上等于不可用。"}),"\n",(0,l.jsxs)(n.p,{children:["在生产环境中我们是不允许 Redis 出现交换行为的，为了限制最大使用内存，Redis 提供了配置参数 ",(0,l.jsx)(n.code,{children:"maxmemory"})," 来限制内存超出期望大小。"]}),"\n",(0,l.jsxs)(n.p,{children:["当实际内存超出 ",(0,l.jsx)(n.code,{children:"maxmemory"})," 时，Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"noeviction"}),"\n不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"volatile-lru"}),"\n尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"volatile-ttl"}),"\n跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"volatile-random"}),"\n跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"allkeys-lru"}),"\n区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"allkeys-random"}),"\n跟上面一样，不过淘汰的策略是随机的 key。"]}),"\n",(0,l.jsx)(n.p,{children:"volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。"}),"\n",(0,l.jsxs)(n.h2,{id:"lru-算法",children:["LRU 算法",(0,l.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#lru-算法",children:"#"})]}),"\n",(0,l.jsx)(n.p,{children:"实现 LRU 算法除了需要 key/value 字典外，还需要附加一个链表，链表中的元素按照一定的顺序进行排列。当空间满的时候，会踢掉链表尾部的元素。当字典的某个元素被访问时，它在链表中的位置会被移动到表头。所以链表的元素排列顺序就是元素最近被访问的时间顺序。"}),"\n",(0,l.jsx)(n.p,{children:"位于链表尾部的元素就是不被重用的元素，所以会被踢掉。位于表头的元素就是最近刚刚被人用过的元素，所以暂时不会被踢。"}),"\n",(0,l.jsx)(n.p,{children:"下面我们使用 Python 的 OrderedDict(双向链表 + 字典) 来实现一个简单的 LRU 算法。"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:"from collections import OrderedDict\n\nclass LRUDict(OrderedDict):\n\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.items = OrderedDict()\n\n    def __setitem__(self, key, value):\n        old_value = self.items.get(key)\n        if old_value is not None:\n            self.items.pop(key)\n            self.items[key] = value\n        elif len(self.items) < self.capacity:\n            self.items[key] = value\n        else:\n            self.items.popitem(last=True)\n            self.items[key] = value\n\n    def __getitem__(self, key):\n        value = self.items.get(key)\n        if value is not None:\n            self.items.pop(key)\n            self.items[key] = value\n        return value\n\n    def __repr__(self):\n        return repr(self.items)\n\n\nd = LRUDict(10)\n\nfor i in range(15):\n    d[i] = i\nprint d\n"})}),"\n",(0,l.jsxs)(n.h2,{id:"近似-lru-算法",children:["近似 LRU 算法",(0,l.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#近似-lru-算法",children:"#"})]}),"\n",(0,l.jsx)(n.p,{children:"Redis 使用的是一种近似 LRU 算法，它跟 LRU 算法还不太一样。之所以不使用 LRU 算法，是因为需要消耗大量的额外的内存，需要对现有的数据结构进行较大的改造。近似 LRU 算法则很简单，在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。Redis 为实现近似 LRU 算法，它给每个 key 增加了一个额外的小字段，这个字段的长度是 24 个 bit，也就是最后一次被访问的时间戳。"}),"\n",(0,l.jsx)(n.p,{children:"上一节提到处理 key 过期方式分为集中处理和懒惰处理，LRU 淘汰不一样，它的处理方式只有懒惰处理。当 Redis 执行写操作时，发现内存超出 maxmemory，就会执行一次 LRU 淘汰算法。这个算法也很简单，就是随机采样出 5(可以配置) 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于 maxmemory 为止。"}),"\n",(0,l.jsx)(n.p,{children:"如何采样就是看 maxmemory-policy 的配置，如果是 allkeys 就是从所有的 key 字典中随机，如果是 volatile 就从带过期时间的 key 字典中随机。每次采样多少个 key 看的是 maxmemory_samples 的配置，默认为 5。"}),"\n",(0,l.jsx)(n.p,{children:"下面是随机 LRU 算法和严格 LRU 算法的效果对比图："}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.img,{src:"https://user-gold-cdn.xitu.io/2018/7/17/164a60daf989f5e2?w=854&h=449&f=png&s=435399",alt:""})}),"\n",(0,l.jsx)(n.p,{children:"图中绿色部分是新加入的 key，深灰色部分是老旧的 key，浅灰色部分是通过 LRU 算法淘汰掉的 key。从图中可以看出采样数量越大，近似 LRU 算法的效果越接近严格 LRU 算法。同时 Redis3.0 在算法中增加了淘汰池，进一步提升了近似 LRU 算法的效果。"}),"\n",(0,l.jsx)(n.p,{children:"淘汰池是一个数组，它的大小是 maxmemory_samples，在每一次淘汰循环中，新随机出来的 key 列表会和淘汰池中的 key 列表进行融合，淘汰掉最旧的一个 key 之后，保留剩余较旧的 key 列表放入淘汰池中留待下一个循环。"}),"\n",(0,l.jsxs)(n.h2,{id:"扩展阅读",children:["扩展阅读",(0,l.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#扩展阅读",children:"#"})]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://yq.aliyun.com/articles/63034",target:"_blank",rel:"noopener noreferrer",children:"《Redis 作为 LRU Cache 的实现》"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://blog.csdn.net/mysqldba23/article/details/68482894",target:"_blank",rel:"noopener noreferrer",children:"《Redis LRU 实现策略》"})}),"\n"]}),"\n",(0,l.jsxs)(n.h2,{id:"思考--作业",children:["思考 & 作业",(0,l.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#思考--作业",children:"#"})]}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"如果你是 Java 用户，试一试用 LinkedHashMap 实现一个 LRU 字典。"}),"\n",(0,l.jsxs)(n.li,{children:["如果你是 Golang 用户，阅读一下 ",(0,l.jsx)(n.a,{href:"https://github.com/hashicorp/golang-lru",target:"_blank",rel:"noopener noreferrer",children:"golang-lru"})," 的源码。"]}),"\n"]})]})}function d(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,r.ah)(),e.components);return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(i,{...e})}):i(e)}let a=d;d.__RSPRESS_PAGE_META={},d.__RSPRESS_PAGE_META["Redis%20%E6%B7%B1%E5%BA%A6%E5%8E%86%E9%99%A9%EF%BC%9A%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%2F26%E6%8B%93%E5%B1%95%205%EF%BC%9A%E4%BC%98%E8%83%9C%E5%8A%A3%E6%B1%B0%20%E2%80%94%E2%80%94%20LRU.md"]={toc:[{text:"LRU 算法",id:"lru-算法",depth:2},{text:"近似 LRU 算法",id:"近似-lru-算法",depth:2},{text:"扩展阅读",id:"扩展阅读",depth:2},{text:"思考 & 作业",id:"思考--作业",depth:2}],title:"26拓展 5：优胜劣汰 —— LRU",headingTitle:"26拓展 5：优胜劣汰 —— LRU",frontmatter:{}}}}]);