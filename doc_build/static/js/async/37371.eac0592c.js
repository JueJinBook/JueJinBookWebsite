"use strict";(self.webpackChunkjue_jin_book_press=self.webpackChunkjue_jin_book_press||[]).push([["37371"],{271929:function(n,s,e){e.r(s),e.d(s,{default:()=>t});var i=e(552676),r=e(740453);let c=e.p+"static/image/b2aeefee3f4cd9920ca754f6b11b4232.46b8fc1d.webp",l=e.p+"static/image/0209a66a65c6bae059c7ec30a019e882.eafc4446.webp",h=e.p+"static/image/b0cc164ec5ed580df9348c0630d870ed.8ef5b931.webp",d=e.p+"static/image/bf07282553f1589a7aa5721e218cc733.dd729dd2.webp",$=e.p+"static/image/7925964d5d11110dcad5a78425db0d1d.d7199546.webp";function x(n){let s=Object.assign({p:"p",strong:"strong",ul:"ul",li:"li",h1:"h1",a:"a",blockquote:"blockquote",img:"img",h2:"h2",h3:"h3",code:"code"},(0,r.ah)(),n.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(s.p,{children:["ChatGPT 模型是一个规模庞大的神经网络模型，第 3-7 节我们重点介绍了 ChatGPT 模型的详细",(0,i.jsx)(s.strong,{children:"结构"}),"。本节到第 11 节，我们将重点介绍如何利用数据",(0,i.jsx)(s.strong,{children:"训练"}),"一个 ChatGPT 模型。"]}),"\n",(0,i.jsxs)(s.p,{children:["ChatGPT 模型的训练过程主要包括",(0,i.jsx)(s.strong,{children:"语言模型的预训练"}),"，根据用户数据",(0,i.jsx)(s.strong,{children:"微调（Finetune）"})," ，使用",(0,i.jsx)(s.strong,{children:"强化学习方法提升模型知识涌现能力"}),"。这几部分的本质都还是",(0,i.jsx)(s.strong,{children:"利用随机梯度下降法，使用数据进行有监督训练"}),"。"]}),"\n",(0,i.jsx)(s.p,{children:"因此，考虑到非 AI 领域读者在阅读上会有困难，本节将介绍一下神经网络的训练流程和基础概念，举一个最简单的例子，帮助你充分理解模型训练的过程。"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"如果你已经具备了 AI 领域的相关知识，则可以跳过本节，继续阅读后续章节；"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"如果你还不具备模型训练的基础知识，则有两种学习方法，第一种是先通读本节内容，然后阅读后续章节，第二种是先跳过本节内容，当阅读到后续章节相关内容时，再返回到本节的基础知识做查阅。"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.h1,{id:"8模型训练基础监督学习与-chatgpt-预训练",children:["8.模型训练基础：监督学习与 ChatGPT 预训练",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#8模型训练基础监督学习与-chatgpt-预训练",children:"#"})]}),"\n",(0,i.jsxs)(s.p,{children:["目前，神经网络最常用的模型训练方法为",(0,i.jsx)(s.strong,{children:"监督学习（Supervised Learning）"})," 。监督学习的目标，是通过给定的输入（ChatGPT 的输入文本）和输出（ChatGPT 的输出文本）数据来学习一个函数，使得对于新的输入数据，可以预测其对应的输出。在监督学习中，我们通常将输入数据称为特征，将输出数据称为标签或目标变量。"]}),"\n",(0,i.jsx)(s.p,{children:"这样说可能还是有些抽象，我们可以打个比方。"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsxs)(s.p,{children:["简单来讲，监督学习就像是一位老师在教学生做题一样。老师会给学生一些已知的",(0,i.jsx)(s.strong,{children:"问题（输入数据）"})," 和",(0,i.jsx)(s.strong,{children:"答案（输出数据）"})," ，让学生通过观察这些问题和答案的关系，学会如何解决新的问题 ",(0,i.jsx)(s.strong,{children:"（模型拟合）"})," ，如考试题等等。"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"具体的监督学习流程如下图所示，蓝色部分为对应模块所使用的常用具体方法。整个模型训练过程，就是准备标注数据，根据模型推理的结果和数据标注结果，使用交叉熵损失函数对比两者的差异，使用梯度下降法更新模型的参数，以此达到模型训练的目标。"}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)("img",{src:$,alt:"8-1.png"})}),"\n",(0,i.jsx)(s.p,{children:"只讲概念还是太抽象了，我们来举一个例子，制作一个最简单的神经网络完成对猫狗特征的分类。"}),"\n",(0,i.jsxs)(s.h2,{id:"神经网络的输入和输出",children:["神经网络的输入和输出",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#神经网络的输入和输出",children:"#"})]}),"\n",(0,i.jsx)(s.p,{children:"在使用监督学习模型训练模型的过程中，必然要依赖已经标注好的数据，这些数据用于喂给模型作为输入，并拿标注好的输出和模型计算得到的输出做对比，以此训练模型。"}),"\n",(0,i.jsx)(s.p,{children:"现在假设我们有两个样本，分别标注好对应的特征和类别："}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"样本 1：体长：0.5 米，身高：0.3 米，食量：0.03 kg；类别：猫"}),"\n",(0,i.jsx)(s.p,{children:"样本 2：体长：1.2 米，身高：0.6 米，食量：0.2 kg；类别：狗"}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"直观地看，一个动物，如果体型小于 0.5 米，身高较矮，食量少，那大概率是猫咪，而如果体型高大，食量大，大概率是一只狗。"}),"\n",(0,i.jsx)(s.p,{children:"根据这些样本，我们构造一个最简单的神经网络（单层前馈全连接线性层），其本质就是一个矩阵乘法运算，对数据做了一次线性变换，其结构如下："}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)("img",{src:d,alt:"8-2.png"}),"\n其中的每一个绿色节点代表一个特征，一个蓝色节点代表一个类别结果，图中的数字代表该节点的编号牌，每一条连接线都是这个微型神经网络的",(0,i.jsx)(s.strong,{children:"权重参数"}),"，这些权重参数就是模型需要通过样本学习和拟合的。"]}),"\n",(0,i.jsx)(s.p,{children:"模型的含义是，针对每一个样本，分别计算其属于猫和狗的值，比较得到的两个值更加偏向哪个类别。"}),"\n",(0,i.jsx)(s.p,{children:"假设这些权重参数分别为：$$w_{00},\xa0w_{01},\xa0w_{10},\xa0w_{11},\xa0w_{20},\xa0w_{21}$$，其中参数的下标即节点的编号。那么，当我们计算样本 1 的结果时，就可以得到："}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"样本 1 的猫类别值：$$class_0 = 0.5w_{00}\xa0+\xa00.3w_{10}\xa0+\xa00.03w_{20}$$"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"样本 1 的狗类别值：$$class_1 = 0.5w_{01}\xa0+\xa00.3w_{11}\xa0+\xa00.03w_{21}$$"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"你可以自己尝试写一下，针对样本 2 的计算式子。"}),"\n",(0,i.jsx)(s.p,{children:"通过比较 $$class_0,\xa0class_1$$ 这两个结果值的大小，如果猫类别值比较大，说明样本属于猫，反之则属于狗。"}),"\n",(0,i.jsxs)(s.h2,{id:"神经网络的预测推理",children:["神经网络的预测推理",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#神经网络的预测推理",children:"#"})]}),"\n",(0,i.jsxs)(s.p,{children:["在模型开始训练之前，首先需要随机初始化一套参数值，用于模型的",(0,i.jsx)(s.strong,{children:"推理"}),"（也叫模型的",(0,i.jsx)(s.strong,{children:"预测"}),"）。在 ChatGPT 中，用户每次调用 ChatGPT 回答一次问题，技术上都叫做一次模型的推理或预测。"]}),"\n",(0,i.jsx)(s.p,{children:"针对猫狗分类的例子，假设我们有一套参数（可以用于模型训练调整的一套值）："}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$ w_{00}=0.5, w_{10}=-1.0,\xa0w_{20}=0.8$$"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$w_{01}=-0.2,\xa0w_{11}=0.6,\xa0w_{21}=-0.5$$"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"由此我们可以分别计算："}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"样本 1 的猫类别值：$$class_{10} = 0.5\xa0\\times\xa00.5\xa0-\xa00.3 \\times\xa01.0\xa0+\xa00.03\xa0\\times\xa00.8\xa0=\xa0-0.026$$"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"样本 1 的狗类别值：$$class_{11} = -0.5\xa0\\times\xa00.2\xa0+\xa00.3 \\times\xa00.6\xa0-\xa00.03\xa0\\times\xa00.5\xa0=\xa00.065$$"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"样本 2 的猫类别值：$$class_{20} = 1.2\xa0\\times\xa00.5\xa0-\xa00.6 \\times\xa01.0\xa0+\xa00.2\xa0\\times\xa00.8\xa0=\xa00.16$$"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"样本 2 的狗类别值：$$class_{21} = -1.2\xa0\\times\xa00.2\xa0+\xa00.6 \\times\xa00.6\xa0-\xa00.2\xa0\\times\xa00.5\xa0=\xa00.02$$"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"那么，怎么判断这些样本经过模型的预测属于哪个类别呢？"}),"\n",(0,i.jsx)(s.p,{children:"所有样本的猫狗类别值，实际上都是 log 化的概率值，通过 softmax 公式，我们可以将上述的取值，转换为真实的概率值。在第 5 节中，我们介绍过 softmax 函数。应用在上述例子，我们可以计算得到：每个样本属于各个类别的概率值："}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$p(猫|样本1) = \\cfrac{exp(-0.026)}{exp(-0.026) + exp(0.065)}\xa0=\xa0\\cfrac{0.974}{0.974 + 1.067}=0.47$$"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$p(狗|样本1) = \\cfrac{exp(0.065)}{exp(-0.026) + exp(0.065)}\xa0=\xa0\\cfrac{1.067}{0.974 + 1.067}=0.53$$"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$p(猫|样本2) = \\cfrac{exp(0.16)}{exp(0.16) + exp(0.02)}\xa0=\xa0\\cfrac{1.173}{1.173 + 1.02}=0.54$$"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$p(狗|样本2) = \\cfrac{exp(0.02)}{exp(0.16) + exp(0.02)}\xa0=\xa0\\cfrac{1.02}{1.173 + 1.02}=0.46$$"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"由此可以判断，从模型预测可以得知，样本 1 更大概率是狗，样本 2 更大概率是猫。这个结果与先前给出的真实标注数据不相符，因此需要计算两者之间不相符的差距。"}),"\n",(0,i.jsxs)(s.h2,{id:"神经网络的损失函数",children:["神经网络的损失函数",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#神经网络的损失函数",children:"#"})]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"损失函数"}),"是机器学习中一个重要概念，用于衡量",(0,i.jsx)(s.strong,{children:"模型预测结果"}),"与",(0,i.jsx)(s.strong,{children:"真实结果"}),"之间的差距，在这个例子中，上述模型参数预测得到的类别和真实的标注类别不一致，这就需要损失函数来衡量。"]}),"\n",(0,i.jsxs)(s.p,{children:["而模型的训练，就是通过优化损失函数来更新模型的参数，使得模型的预测结果更加准确。常见的损失函数是",(0,i.jsx)(s.strong,{children:"交叉熵"})," ",(0,i.jsx)(s.strong,{children:"（Cross"})," ",(0,i.jsx)(s.strong,{children:"Entropy"})," ",(0,i.jsx)(s.strong,{children:"）"})," ，我们也以该损失函数为例，对猫狗分类的例子做介绍。"]}),"\n",(0,i.jsxs)(s.p,{children:["这里就用到了",(0,i.jsx)(s.strong,{children:"交叉熵损失函数"}),"。其公式形式为："]}),"\n",(0,i.jsx)(s.p,{children:"$$J(w) = -\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{j=1}^{k}y_j^{(i)}\\log(h_{w}(x^{(i)})_j)$$"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"其中，$$m$$表示样本数量，例子中总共有 2 个样本；"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$k$$表示类别数量，在这个例子中$$k$$值为 2，即猫和狗两种类别；"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$y_j^{(i)}$$表示第 $$i$$个样本的真实标签是否属于第 $$j$$个类别，是则为 1，否则为 0；"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"$$h_{w}(x^{(i)})_j$$表示模型对第 $$i$$个样本属于第 $$j$$个类别的预测概率。"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"这个公式看起来的确有点抽象，我们来计算一下上面的猫狗分类例子，加深理解。"}),"\n",(0,i.jsx)(s.p,{children:"对于样本 1，$$J_1(w) = -1.0\xa0\\times \\log(0.47)\xa0+\xa00\xa0\\times\xa0\\log(0.53)=0.75\xa0$$"}),"\n",(0,i.jsx)(s.p,{children:"对于样本 2，$$J_2(w) = 0.0\xa0\\times \\log(0.54)\xa0-\xa01.0\xa0\\times\xa0\\log(0.46)=0.776\xa0$$"}),"\n",(0,i.jsx)(s.p,{children:"因此，总和损失值为：$$J(w) = \\cfrac{J_1(w)+J_2(w)}{2}=0.763$$"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsxs)(s.p,{children:["交叉熵是一个",(0,i.jsx)(s.strong,{children:"信息论"}),"中的概念，它衡量了两个概率分布之间的差异（距离），这个值一定是大于 0 的正实数。若两个概率分布十分接近，则交叉熵值越小，越逼近于 0，反之则越大。而模型预测的结果和标签标注的结果，本身就是两个概率分布。"]}),"\n",(0,i.jsxs)(s.p,{children:["关于信息论的基础知识，你可以参考",(0,i.jsx)(s.a,{href:"https://mp.weixin.qq.com/s/YP3SixzbgWPpvx-1xzeodQ",target:"_blank",rel:"noopener noreferrer",children:"【信息熵、交叉熵、相对熵】"}),"一文阅读学习，其中详细介绍了信息论如何应用在监督学习中。"]}),"\n"]}),"\n",(0,i.jsxs)(s.h2,{id:"梯度下降法",children:["梯度下降法",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#梯度下降法",children:"#"})]}),"\n",(0,i.jsx)(s.p,{children:"从上面的例子中我们了解到，若随机设定的模型权重，会导致模型对样本的类别判断产生错误。这个错误值的大小即交叉熵损失函数值。"}),"\n",(0,i.jsxs)(s.p,{children:["那么，针对上述例子，接下来就是让模型能够根据给出的两条样本数据训练模型、更新参数权重，正确地分出每一个样本是猫还是狗。此时，我们就用到了",(0,i.jsx)(s.strong,{children:"梯度下降法"}),"。"]}),"\n",(0,i.jsxs)(s.h3,{id:"定义",children:["定义",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#定义",children:"#"})]}),"\n",(0,i.jsx)(s.p,{children:"梯度下降法是一种常用的优化算法，用于求解函数的最小值。在机器学习中，我们通常使用梯度下降法来更新模型的参数，使得损失函数最小化。 梯度下降法的基本思想是沿着函数的负梯度方向不断迭代，直到达到最小值。"}),"\n",(0,i.jsxs)(s.p,{children:["具体来说，我们首先随机初始化模型的参数，然后计算损失函数$$J(w)$$对于每个参数的",(0,i.jsx)(s.strong,{children:"偏导数"}),"，即",(0,i.jsx)(s.strong,{children:"梯度"}),"$$\\nabla\xa0J(w)$$。接着，我们沿着梯度的反方向更新参数，使得损失函数逐渐减小。这个过程可以通过以下公式表示：$$w=w-\\alpha\xa0\\times\xa0\\nabla\xa0J(w)$$。"]}),"\n",(0,i.jsx)(s.p,{children:"公式比较抽象，我们仍以上述例子阐述一下怎么进行梯度下降。"}),"\n",(0,i.jsxs)(s.h3,{id:"梯度下降法训练实施过程",children:["梯度下降法训练实施过程",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#梯度下降法训练实施过程",children:"#"})]}),"\n",(0,i.jsx)(s.p,{children:"对于样本 1，其真实的类别应该是猫。然而，模型以 0.47 的概率认为它是猫，以 0.53 的概率认为它是狗，模型更偏向该样本被分类为狗。"}),"\n",(0,i.jsx)(s.p,{children:"因此，我们的调整目标，是希望模型对于输出猫的概率$$p(猫|样本1)$$更大，对于狗的输出概率$$p(狗|样本1)$$更小。而 $$p(猫|样本1)$$ 和 $$p(狗|样本1)$$ 概率值，是由 $$class_{10}$$ 和 $$class_{11}$$ 值决定的，当 $$class_{10}$$ 值越大时，$$p(猫|样本1)$$ 概率值也就越大，相应的 $$p(狗|样本1)$$ 概率值也就越小。因此，我们应当使得 $$class_{10}$$ 值尽量大。"}),"\n",(0,i.jsxs)(s.p,{children:["而对于样本 1，当 $$w_{00}$$ 权重参数值越大时，$$class_{10}$$ 值也就越大。因此，我们应当使  $$w_{00}$$ 值尽量大。其中，当我们",(0,i.jsx)(s.strong,{children:"把"})," $$w_{00}=0.5$$ ",(0,i.jsx)(s.strong,{children:"权重值调大"}),"，例如，改为 $$w_{00}=2$$ 之后，我们再计算 $$class_{10} = 0.5\xa0\\times\xa02\xa0-\xa00.3 \\times\xa01.0\xa0+\xa00.03\xa0\\times\xa00.8\xa0=\xa00.724$$。"]}),"\n",(0,i.jsx)(s.p,{children:"而 $$class_{11} = -0.5\xa0\\times\xa00.2\xa0+\xa00.3 \\times\xa00.6\xa0-\xa00.03\xa0\\times\xa00.5\xa0=\xa00.065$$\n保持不变。此时，再计算概率值："}),"\n",(0,i.jsx)(s.p,{children:"$$p(猫|样本1) = \\cfrac{exp(0.724)}{exp(0.724) + exp(0.065)}\xa0=\xa0\\cfrac{2.062}{2.062 + 1.067}=0.659$$"}),"\n",(0,i.jsx)(s.p,{children:"$$p(狗|样本1) = \\cfrac{exp(0.065)}{exp(0.724) + exp(0.065)}\xa0=\xa0\\cfrac{1.067}{2.062 + 1.067}=0.341$$"}),"\n",(0,i.jsx)(s.p,{children:"至此，我们通过调整 $$w_{00}$$ 的值的大小，实现了模型预测样本 1 更加偏向类别为猫，概率为 65.9%，相应的分类为狗的概率是 34.1%。根据调整过的模型参数，重新计算损失函数值$$J(w) = 0.506$$（过程略去，读者可以自行尝试），损失函数的下降，表明模型的训练朝着正确的方向前进。"}),"\n",(0,i.jsx)(s.p,{children:"按此方式，我们可以把样本 2 以同样的方式进行参数迭代，除了$$w_{00}$$之外，$$w_{01},\xa0w_{10},\xa0w_{11},\xa0w_{20},\xa0w_{21}$$所有参数都可以按此方式进行迭代训练。循环往复，就可以通过给定的数据，得到一个优质的模型。"}),"\n",(0,i.jsxs)(s.p,{children:["这样一来，我们就",(0,i.jsx)(s.strong,{children:"通过调整模型参数权重，实现了模型的训练任务"}),"。实际上，上述整个过程就是在利用梯度下降法实现模型的训练。当我们由 $$p(猫|样本1)\xa0\\to\xa0class_{10}\xa0\\to\xa0w_{00}$$ 一步步推导出每一个变量的变化时，就是在用链式求导法则做偏导数计算。"]}),"\n",(0,i.jsx)(s.p,{children:"实际上，模型的训练过程就是一个损失函数值不断下降的过程，这个过程我们在第 5 节中简要提到过。如果把损失值比作一座山的海拔高度，那么模型训练过程就是从一座高山的山峰逐渐下来。"}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)("img",{src:h,alt:""})}),"\n",(0,i.jsx)(s.p,{children:"图中的每一个黑色十字都代表一次迭代，正如我们上述例子中$$w_{00}:0.5\xa0\\to\xa02$$。经过层层迭代，模型的损失函数值下降到一个极小点，这个极小点就意味着完成了训练。而图中的两条黑色线路，代表了模型参数的下降方向是随机的，这个随机性由样本和最初设定的$$w$$参数共同决定。"}),"\n",(0,i.jsxs)(s.h1,{id:"chatgpt-的预训练过程",children:["ChatGPT 的预训练过程",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#chatgpt-的预训练过程",children:"#"})]}),"\n",(0,i.jsx)(s.p,{children:"了解了上述模型的训练过程，我们就可以解释 ChatGPT 模型的训练过程了。第 1 节中我们初步了解到，ChatGPT 是经过两个训练步骤得到的。"}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)("img",{src:l,alt:"8-3.png"})}),"\n",(0,i.jsx)(s.p,{children:"在第 4 节中，我们介绍了 ChatGPT 模型以 token 序列的 embedding 作为输入传入模型。"}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)("img",{src:c,alt:"8-4.png"})}),"\n",(0,i.jsx)(s.p,{children:"ChatGPT 模型的输出和前面提到的猫狗分类也非常相似。在猫狗分类中，总共对每一条样本预测分别属于猫、或狗的概率，即$$p(猫|样本)$$和$$p(狗|样本)$$。而在 ChatGPT 预训练中，以下面为例："}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"例句：jionlp 是一个好用的开源_____"}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["那么，根据 ChatGPT 建模形式，模型的输入是 ",(0,i.jsx)(s.code,{children:"jionlp 是一个好用的开源"}),"，需要让模型输出下一个字是什么。"]}),"\n",(0,i.jsxs)(s.p,{children:["假设我们的 token 词表总共有 50000 个。ChatGPT 模型输出了一个 50000 维度的向量，$$d_{50000}=[0.123, -1.092, ... , 0.037]$$，其中每一个维度值都对应了一个 token，假设第 3333 维度对应了词表 token ",(0,i.jsx)(s.code,{children:"软"}),"，而这一维度值是最大的，我们就可以将此 token 抽取出来，作为结果放置在例句后面。反复执行这一操作，就可以填补完整句子："]}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"例句：jionlp 是一个好用的开源 软件"}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"以概率公式表示，即 $$p(软|jionlp是一个好用的开源)$$ 和 $$p(件|jionlp是一个好用的开源软)$$。"}),"\n",(0,i.jsx)(s.p,{children:"除此之外，ChatGPT 的训练流程和上述的猫狗分类没有本质差别。"}),"\n",(0,i.jsxs)(s.h1,{id:"总结",children:["总结",(0,i.jsx)(s.a,{className:"header-anchor","aria-hidden":"true",href:"#总结",children:"#"})]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"监督学习是根据数据，对模型参数进行拟合，在神经网络模型中非常常用。"}),"\n",(0,i.jsx)(s.li,{children:"监督学习最常用的损失函数是交叉熵。"}),"\n",(0,i.jsx)(s.li,{children:"监督学习采用梯度下降法进行模型的参数训练。"}),"\n",(0,i.jsx)(s.li,{children:"ChatGPT 的预训练就是一个监督学习过程。"}),"\n"]})]})}function j(){let n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:s}=Object.assign({},(0,r.ah)(),n.components);return s?(0,i.jsx)(s,{...n,children:(0,i.jsx)(x,{...n})}):x(n)}let t=j;j.__RSPRESS_PAGE_META={},j.__RSPRESS_PAGE_META["%E4%BA%BA%E4%BA%BA%E9%83%BD%E8%83%BD%E7%9C%8B%E6%87%82%E7%9A%84%20ChatGPT%20%E5%8E%9F%E7%90%86%E8%AF%BE%2F8.%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%9F%BA%E7%A1%80%EF%BC%9A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%20ChatGPT%20%E9%A2%84%E8%AE%AD%E7%BB%83.md"]={toc:[{text:"神经网络的输入和输出",id:"神经网络的输入和输出",depth:2},{text:"神经网络的预测推理",id:"神经网络的预测推理",depth:2},{text:"神经网络的损失函数",id:"神经网络的损失函数",depth:2},{text:"梯度下降法",id:"梯度下降法",depth:2},{text:"定义",id:"定义",depth:3},{text:"梯度下降法训练实施过程",id:"梯度下降法训练实施过程",depth:3}],title:"总结",headingTitle:"总结",frontmatter:{}}}}]);