"use strict";(self.webpackChunkjue_jin_book_press=self.webpackChunkjue_jin_book_press||[]).push([["18224"],{475969:function(n,e,t){t.r(e),t.d(e,{default:()=>o});var r=t(552676),c=t(740453);let s=t.p+"static/image/c92c2351e7b5ac6e52e65796fd7aa158.cee45189.webp",i=t.p+"static/image/009320c178fce249b223c3eb56d9bc54.ea1736c2.webp";function a(n){let e=Object.assign({h1:"h1",a:"a",blockquote:"blockquote",p:"p",code:"code",ol:"ol",li:"li",table:"table",thead:"thead",tr:"tr",th:"th",tbody:"tbody",td:"td",h2:"h2",pre:"pre",br:"br",img:"img"},(0,c.ah)(),n.components);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(e.h1,{id:"9-embedding大规模数据的预处理",children:["9-Embedding：大规模数据的预处理",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#9-embedding大规模数据的预处理",children:"#"})]}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsxs)(e.p,{children:["本章对应源代码：",(0,r.jsx)(e.a,{href:"https://github.com/RealKai42/langchainjs-juejin/blob/main/splitter.ipynb",target:"_blank",rel:"noopener noreferrer",children:"https://github.com/RealKai42/langchainjs-juejin/blob/main/splitter.ipynb"})]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"受限于常见 llm 的上下文大小，例如 gpt3.5t 是 16k、gpt4t 是 128k，我们并不能把完整的数据整个塞到对话的上下文中。并且，即使数据源接近于 llm 的上下文窗口大小，llm 在读取数据时很容易出现分神，或者忽略其中部分细节的问题。所以，我们需要对加载进来的数据切分，切分成比较小的块，然后根据对话的内容，将最关联的数据塞到 llm 的上下文中，来强化 llm 输出的专注性和质量。"}),"\n",(0,r.jsx)(e.p,{children:"对于分割来说，我们的目的就是将文本切分成多个文档块，每个文档块的内部语义相关，并且与其他块具有独立性，能够独立的表达和阐述某个信息。这其中有非常多复杂性，对于 RAG 来说，语意切分的质量决定了对话时 llm 获取信息的质量，也就决定了生成答案的质量。"}),"\n",(0,r.jsxs)(e.p,{children:["而从宏观角度来看 ",(0,r.jsx)(e.code,{children:"TextSplitter"})," 他的工作方式非常的好理解"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"首先是根据预设的分块逻辑，将内容切分成多个块，并且每个块是表达独立的语意。对于一般文本，你可以理解成切分到句子这一级，因为切分到词已经失去了语意性。"}),"\n",(0,r.jsx)(e.li,{children:"开始将这些块进行组装，一直到用户预设的块大小限制。"}),"\n",(0,r.jsx)(e.li,{children:"在组装完一个块后，会根据相同的逻辑去组装另一个块。并且在组装时，会根据用户设定的块之间的重叠大小，来给文档块添加与上下文档块的重叠部分。 例如第一个块是 AABBCC,那么第二个块就是 CCDDEE，第三个块就是  EEFFGG。"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"重叠部分是因为，理想情况下我们是希望能够切分成语意相关并且完全独立的文档块，但受限于自然语言的特殊性，这点很难做到，所以为了减少切分时造成语意的中断，我们会人为的给切分块加入跟前后文档块重叠的部分，来减少语意中断的影响。"}),"\n",(0,r.jsx)(e.p,{children:"在理解切分的逻辑后，当你需要根据你的数据类型进行切分时，就可以根据以下几个维度去思考应该使用什么样的切分器："}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"目标文档类型是什么？"}),"\n",(0,r.jsx)(e.li,{children:"如何衡量切分后文档块的大小?"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"从先有的 langchain 提供的切分能力来看，我认为最重要的第一点，也就是根据文档类型选择需要的切分工具。langchain 目前提供的切分工具有："}),"\n",(0,r.jsxs)(e.table,{children:["\n",(0,r.jsxs)(e.thead,{children:["\n",(0,r.jsxs)(e.tr,{children:["\n",(0,r.jsx)(e.th,{children:"名称"}),"\n",(0,r.jsx)(e.th,{children:"说明"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.tbody,{children:["\n",(0,r.jsxs)(e.tr,{children:["\n",(0,r.jsx)(e.td,{children:"Recursive"}),"\n",(0,r.jsxs)(e.td,{children:["根据给定的切分字符（例如 ",(0,r.jsx)(e.code,{children:"\\n\\n"}),"、",(0,r.jsx)(e.code,{children:"\\n"}),"等），递归的切分"]}),"\n"]}),"\n",(0,r.jsxs)(e.tr,{children:["\n",(0,r.jsx)(e.td,{children:"HTML"}),"\n",(0,r.jsx)(e.td,{children:"根据 html 特定字符进行切分"}),"\n"]}),"\n",(0,r.jsxs)(e.tr,{children:["\n",(0,r.jsx)(e.td,{children:"Markdown"}),"\n",(0,r.jsx)(e.td,{children:"根据 md 的特定字符进行切分"}),"\n"]}),"\n",(0,r.jsxs)(e.tr,{children:["\n",(0,r.jsx)(e.td,{children:"Code"}),"\n",(0,r.jsx)(e.td,{children:"根据不同编程语言的特定字符进行切分"}),"\n"]}),"\n",(0,r.jsxs)(e.tr,{children:["\n",(0,r.jsx)(e.td,{children:"Token"}),"\n",(0,r.jsx)(e.td,{children:"根据文本块的 token 数据进行切分"}),"\n"]}),"\n",(0,r.jsxs)(e.tr,{children:["\n",(0,r.jsx)(e.td,{children:"Character"}),"\n",(0,r.jsx)(e.td,{children:"根据用户给定的字符进行切割"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.h2,{id:"recursivecharactertextsplitter",children:["RecursiveCharacterTextSplitter",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#recursivecharactertextsplitter",children:"#"})]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.code,{children:"RecursiveCharacterTextSplitter"}),"，这是最常用的切分工具，他根据内置的一些字符对原始文本进行递归的切分，来保持相关的文本片段相邻，保持切分结果内部的语意相关性。"]}),"\n",(0,r.jsxs)(e.p,{children:["默认的分隔符列表是 ",(0,r.jsx)(e.code,{children:'["\\n\\n", "\\n", " ", ""]'}),"，你可以认为它切割的逻辑就是，先把把原文切分成段落，然后切分成句子、单词，然后根据我们定义的每个 chunk 的大小，尽可能放在一起，来保证语意的连贯性和相关性。"]}),"\n",(0,r.jsx)(e.p,{children:"最影响切分质量的就是两个参数："}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"chunkSize"})," 其定义了切分结果中每个块的大小，这决定了 LLM 在每个块中能够获取的上下文。需要根据数据源的内容类型来制定，如果太大一个块中可能包含多个信息，容易导致 LLM 分神，并且这个结果会作为对话的上下文输入给 LLM，导致 token 增加从而增加成本。如果过小，则可能一个块中无法包含完整的信息，影响输出的质量。"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"chunkOverlap"})," 定义了，块和块之间重叠部分的大小，因为在自然语言中内容是连续性的，分块时一定的重叠可以让文本不会在奇怪的地方被切割，并让内容保留一定的上下文。较大的 ",(0,r.jsx)(e.code,{children:"chunkOverlap"})," 可以确保文本不会被奇怪地分割，但可能会导致重复提取信息，而较小的 ",(0,r.jsx)(e.code,{children:"chunkOverlap"})," 可以减少重复提取信息的可能性，但可能会导致文本在奇怪的地方切割。"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"我们使用这来切分一下《孔乙己》这个短篇小说"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";\nimport { TextLoader } from "langchain/document_loaders/fs/text";\n\nconst loader = new TextLoader("data/kong.txt");\nconst docs = await loader.load();\n\nconst splitter = new RecursiveCharacterTextSplitter({\n    chunkSize: 64,\n    chunkOverlap: 0,\n  });\n\nconst splitDocs = await splitter.splitDocuments(docs);\n'})}),"\n",(0,r.jsxs)(e.p,{children:["现在 ",(0,r.jsx)(e.code,{children:"splitDocs"})," 存储的就是切割后的文本，我们看一下效果"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'[\n  Document {\n    pageContent: "鲁镇的酒店的格局，是和别处不同的：都是当街一个曲尺形的大柜台，柜里面预备着热水，可以随时温酒。做工的人，傍午傍晚散了工，每每花四",\n    metadata: { source: "data/kong.txt", loc: { lines: { from: 1, to: 1 } } }\n  },\n  Document {\n    pageContent: "文铜钱，买一碗酒，——这是二十多年前的事，现在每碗要涨到十文，——靠柜外站着，热热的喝了休息；倘肯多花一文，便可以买一碟盐煮笋，",\n    metadata: { source: "data/kong.txt", loc: { lines: { from: 1, to: 1 } } }\n  },\n  Document {\n    pageContent: "或者茴香豆，做下酒物了，如果出到十几文，那就能买一样荤菜，但这些顾客，多是短衣帮，大抵没有这样阔绰。只有穿长衫的，才踱进店面隔壁",\n    metadata: { source: "data/kong.txt", loc: { lines: { from: 1, to: 1 } } }\n  },\n  Document {\n    pageContent: "的房子里，要酒要菜，慢慢地坐喝。",\n    metadata: { source: "data/kong.txt", loc: { lines: { from: 1, to: 1 } } }\n  },\n  Document {\n    pageContent: "我从十二岁起，便在镇口的咸亨酒店里当伙计，掌柜说，我样子太傻，怕侍候不了长衫主顾，就在外面做点事罢。外面的短衣主顾，虽然容易说",\n    metadata: { source: "data/kong.txt", loc: { lines: { from: 3, to: 3 } } }\n  },\n  ...\n  ]\n'})}),"\n",(0,r.jsxs)(e.p,{children:["因为原始数据中，一行就是一段，中间用空行分割，所有前几个 ",(0,r.jsx)(e.code,{children:"Document"})," 的 meta 都是 ",(0,r.jsx)(e.code,{children:"lines: { from: 1, to: 1 }"}),"。",(0,r.jsx)(e.br,{}),"\n","我们可以使用 ",(0,r.jsx)(e.a,{href:"https://chunkviz.up.railway.app/",target:"_blank",rel:"noopener noreferrer",children:"ChunkViz"})," 去可视化的看一下效果。（注意，这里将 chunkSize 只是为了教学，一般不会设置的这么低）"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:i,alt:"CleanShot 2024-03-25 at 18.35.08@2x.png"})}),"\n",(0,r.jsxs)(e.p,{children:["然后，我们可以尝试去设置 ",(0,r.jsx)(e.code,{children:"chunkOverlap"})," 去看，文档块之间的重叠是如何设置和形成的，"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:"const splitter = new RecursiveCharacterTextSplitter({\n    chunkSize: 64,\n    chunkOverlap: 16,\n  });\n\nconst splitDocs = await splitter.splitDocuments(docs);\n"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'[\n  Document {\n    pageContent: "鲁镇的酒店的格局，是和别处不同的：都是当街一个曲尺形的大柜台，柜里面预备着热水，可以随时温酒。做工的人，傍午傍晚散了工，每每花四",\n    metadata: { source: "data/kong.txt", loc: { lines: { from: 1, to: 1 } } }\n  },\n  Document {\n    pageContent: "工的人，傍午傍晚散了工，每每花四文铜钱，买一碗酒，——这是二十多年前的事，现在每碗要涨到十文，——靠柜外站着，热热的喝了休息；倘",\n    metadata: { source: "data/kong.txt", loc: { lines: { from: 1, to: 1 } } }\n  },\n  Document {\n    pageContent: "—靠柜外站着，热热的喝了休息；倘肯多花一文，便可以买一碟盐煮笋，或者茴香豆，做下酒物了，如果出到十几文，那就能买一样荤菜，但这些",\n    metadata: { source: "data/kong.txt", loc: { lines: { from: 1, to: 1 } } }\n  },\n  ...\n]\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)("img",{src:s,alt:"CleanShot 2024-03-28 at 00.18.59@2x.png"})}),"\n",(0,r.jsx)(e.p,{children:"图中墨绿色的部分就是两个文档块之间重叠的部分。"}),"\n",(0,r.jsxs)(e.p,{children:["你可以认为，",(0,r.jsx)(e.code,{children:"RecursiveCharacterTextSplitter"})," 是所有切分块的基础，也是当开始一个文本切割任务时，最推荐作为开始的工具。理解了这个切分函数的行为模式，也就是理解了切分函数的工作模式。因为这是比较通用的切分函数，可以在完整实现所有 Chain 之后，再去看切分函数是否影响了最终的质量，来决定是调整切分的参数，还是选择其他切分工具。"]}),"\n",(0,r.jsxs)(e.p,{children:["切分函数最核心的两个参数是 ",(0,r.jsx)(e.code,{children:"chunkSize"})," 和 ",(0,r.jsx)(e.code,{children:"chunkOverlap"}),"，在市面上你会看到很多教你如何设置这个思路，都是定性的讨论，有各种逻辑和思路。但就具体实践来说，先设定为默认的 1000 和 200，然后使用 ChunkViz 去检查部分结果是否符合预期，然后根据人类对语意的理解去调整到一个合适的值。然后，在整个 chain 完成后，根据最终结果的质量和生成过程中的 log 去查找是哪部分影响了最终的结果质量，再去决定是否调整这两个参数。因为自然语言的特殊性，其实是很难找到一个完美的参数值，在早期过多精力和时间消耗在这的价值不大。"]}),"\n",(0,r.jsxs)(e.p,{children:["可以看到我们花了大量的篇幅去讲解 ",(0,r.jsx)(e.code,{children:"RecursiveCharacterTextSplitter"}),"，在大家理解了这个基石一般的切分函数后，剩下的常用切分函数就很好理解了，就是对不同目标文档进行了优化。"]}),"\n",(0,r.jsxs)(e.h2,{id:"code",children:["Code",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#code",children:"#"})]}),"\n",(0,r.jsx)(e.p,{children:"因为 langchain 所支持的语言是一直在变动的，可以通过这个函数查询目前支持的语言"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import { SupportedTextSplitterLanguages } from "langchain/text_splitter";\n\nconsole.log(SupportedTextSplitterLanguages); \n'})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'[\n  "cpp",      "go",\n  "java",     "js",\n  "php",      "proto",\n  "python",   "rst",\n  "ruby",     "rust",\n  "scala",    "swift",\n  "markdown", "latex",\n  "html",     "sol"\n]\n'})}),"\n",(0,r.jsx)(e.p,{children:"可以看到常见的语言都是支持的，我们以 js 为例去看看切分代码是什么效果"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";\n\nconst js = `\nfunction myFunction(name,job){\n	console.log("Welcome " + name + ", the " + job);\n}\n\nmyFunction(\'Harry Potter\',\'Wizard\')\n\nfunction forFunction(){\n	for (let i=0; i<5; i++){\n        console.log("这个数字是" + i)\n	}\n}\n\nforFunction()\n`;\n\nconst splitter = RecursiveCharacterTextSplitter.fromLanguage("js", {\n  chunkSize: 64,\n  chunkOverlap: 0,\n});\nconst jsOutput = await splitter.createDocuments([js]);\n'})}),"\n",(0,r.jsx)(e.p,{children:"输出"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'[\n  Document {\n    pageContent: "function myFunction(name,job){",\n    metadata: { loc: { lines: { from: 2, to: 2 } } }\n  },\n  Document {\n    pageContent: \'console.log("Welcome " + name + ", the " + job);\\n}\',\n    metadata: { loc: { lines: { from: 3, to: 4 } } }\n  },\n  Document {\n    pageContent: "myFunction(\'Harry Potter\',\'Wizard\')",\n    metadata: { loc: { lines: { from: 6, to: 6 } } }\n  },\n  Document {\n    pageContent: "function forFunction(){\\n\\tfor (let i=0; i<5; i++){",\n    metadata: { loc: { lines: { from: 8, to: 9 } } }\n  },\n  Document {\n    pageContent: \'console.log("这个数字是" + i)\\n\\t}\\n}\',\n    metadata: { loc: { lines: { from: 10, to: 12 } } }\n  },\n  Document {\n    pageContent: "forFunction()",\n    metadata: { loc: { lines: { from: 14, to: 14 } } }\n  }\n]\n'})}),"\n",(0,r.jsxs)(e.p,{children:["从调用方式上，你也能猜到，对 js 的分割本质上就是将 js 中常见的切分代码的特定字符传给 ",(0,r.jsx)(e.code,{children:"RecursiveCharacterTextSplitter"}),"，然后还是根据 ",(0,r.jsx)(e.code,{children:"Recursive"})," 的逻辑进行切分，跟对正常 text 切分的逻辑是一样的。"]}),"\n",(0,r.jsxs)(e.h2,{id:"token",children:["Token",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#token",children:"#"})]}),"\n",(0,r.jsx)(e.p,{children:"这个切分函数使用场景并不多，因为切分的时候并不是根据各种符号（例如标点）等进行切分来尝试保持语义性，就是根据 token 的数量进行切分，仅适合对 token 比较敏感的场景，或者与其他切分函数组合使用。"}),"\n",(0,r.jsx)(e.p,{children:"具体到使用场景，用起来很方便"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'import { TokenTextSplitter } from "langchain/text_splitter";\n\nconst text = "I stand before you today the representative of a family in grief, in a country in mourning before a world in shock.";\n\nconst splitter = new TokenTextSplitter({\n  chunkSize: 10,\n  chunkOverlap: 0,\n});\n\nconst docs = await splitter.createDocuments([text]);\n'})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-js",children:'[\n  Document {\n    pageContent: "I stand before you today the representative of a family",\n    metadata: { loc: { lines: { from: 1, to: 1 } } }\n  },\n  Document {\n    pageContent: " in grief, in a country in mourning before a",\n    metadata: { loc: { lines: { from: 1, to: 1 } } }\n  },\n  Document {\n    pageContent: " world in shock.",\n    metadata: { loc: { lines: { from: 1, to: 1 } } }\n  }\n]\n'})}),"\n",(0,r.jsxs)(e.p,{children:["其中 ",(0,r.jsx)(e.code,{children:"chunkSize"})," 和 ",(0,r.jsx)(e.code,{children:"chunkOverlap"})," 的逻辑跟 ",(0,r.jsx)(e.code,{children:"RecursiveCharacterTextSplitter"})," 的定义是一样的"]}),"\n",(0,r.jsxs)(e.h2,{id:"小结",children:["小结",(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#小结",children:"#"})]}),"\n",(0,r.jsxs)(e.p,{children:["本节我们介绍了切分函数这个概念，方便将较长的文档切分成长度合适、语意相关的模块，其中最重要的就是理解 ",(0,r.jsx)(e.code,{children:"chunkSize"})," 和 ",(0,r.jsx)(e.code,{children:"chunkOverlap"})," 这两个概念，理解其现实含义和效果，并在实战中根据情况进行调整。"]})]})}function l(){let n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:e}=Object.assign({},(0,c.ah)(),n.components);return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(a,{...n})}):a(n)}let o=l;l.__RSPRESS_PAGE_META={},l.__RSPRESS_PAGE_META["%E4%BB%8E%E5%89%8D%E7%AB%AF%E5%88%B0%20AI%EF%BC%9ALangChain.js%20%E5%85%A5%E9%97%A8%E5%92%8C%E5%AE%9E%E6%88%98_online%2F9-Embedding%EF%BC%9A%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86.md"]={toc:[{text:"RecursiveCharacterTextSplitter",id:"recursivecharactertextsplitter",depth:2},{text:"Code",id:"code",depth:2},{text:"Token",id:"token",depth:2},{text:"小结",id:"小结",depth:2}],title:"9-Embedding：大规模数据的预处理",headingTitle:"9-Embedding：大规模数据的预处理",frontmatter:{}}}}]);