"use strict";(self.webpackChunkjue_jin_book_press=self.webpackChunkjue_jin_book_press||[]).push([["96571"],{452355:function(e,n,s){s.r(n),s.d(n,{default:()=>r});var h=s(552676),c=s(740453);function d(e){let n=Object.assign({h1:"h1",a:"a",p:"p",code:"code",pre:"pre",strong:"strong",ol:"ol",li:"li",h2:"h2",img:"img"},(0,c.ah)(),e.components);return(0,h.jsxs)(h.Fragment,{children:[(0,h.jsxs)(n.h1,{id:"10应用-9大海捞针--scan",children:["10应用 9：大海捞针 —— Scan",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#10应用-9大海捞针--scan",children:"#"})]}),"\n",(0,h.jsx)(n.p,{children:"在平时线上 Redis 维护工作中，有时候需要从 Redis 实例成千上万的 key 中找出特定前缀的 key 列表来手动处理数据，可能是修改它的值，也可能是删除 key。这里就有一个问题，如何从海量的 key 中找出满足特定前缀的 key 列表来？"}),"\n",(0,h.jsxs)(n.p,{children:["Redis 提供了一个简单暴力的指令 ",(0,h.jsx)(n.code,{children:"keys"})," 用来列出所有满足特定正则字符串规则的 key。"]}),"\n",(0,h.jsx)(n.pre,{children:(0,h.jsx)(n.code,{children:'127.0.0.1:6379> set codehole1 a\nOK\n127.0.0.1:6379> set codehole2 b\nOK\n127.0.0.1:6379> set codehole3 c\nOK\n127.0.0.1:6379> set code1hole a\nOK\n127.0.0.1:6379> set code2hole b\nOK\n127.0.0.1:6379> set code3hole b\nOK\n127.0.0.1:6379> keys *\n1) "codehole1"\n2) "code3hole"\n3) "codehole3"\n4) "code2hole"\n5) "codehole2"\n6) "code1hole"\n127.0.0.1:6379> keys codehole*\n1) "codehole1"\n2) "codehole3"\n3) "codehole2"\n127.0.0.1:6379> keys code*hole\n1) "code3hole"\n2) "code2hole"\n3) "code1hole"\n'})}),"\n",(0,h.jsxs)(n.p,{children:["这个指令使用非常简单，提供一个简单的正则字符串即可，但是有很明显的两个",(0,h.jsx)(n.strong,{children:"缺点"}),"。"]}),"\n",(0,h.jsxs)(n.ol,{children:["\n",(0,h.jsx)(n.li,{children:"没有 offset、limit 参数，一次性吐出所有满足条件的 key，万一实例中有几百 w 个 key 满足条件，当你看到满屏的字符串刷的没有尽头时，你就知道难受了。"}),"\n",(0,h.jsx)(n.li,{children:"keys 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，这个指令就会导致 Redis 服务卡顿，所有读写 Redis 的其它的指令都会被延后甚至会超时报错，因为 Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才可以继续。"}),"\n"]}),"\n",(0,h.jsx)(n.p,{children:"面对这两个显著的缺点该怎么办呢？"}),"\n",(0,h.jsxs)(n.p,{children:["Redis 为了解决这个问题，它在 2.8 版本中加入了大海捞针的指令——",(0,h.jsx)(n.code,{children:"scan"}),"。",(0,h.jsx)(n.code,{children:"scan"})," 相比 ",(0,h.jsx)(n.code,{children:"keys"})," 具备有以下特点:"]}),"\n",(0,h.jsxs)(n.ol,{children:["\n",(0,h.jsx)(n.li,{children:"复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程;"}),"\n",(0,h.jsx)(n.li,{children:"提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少;"}),"\n",(0,h.jsx)(n.li,{children:"同 keys 一样，它也提供模式匹配功能;"}),"\n",(0,h.jsx)(n.li,{children:"服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数;"}),"\n",(0,h.jsx)(n.li,{children:"返回的结果可能会有重复，需要客户端去重复，这点非常重要;"}),"\n",(0,h.jsx)(n.li,{children:"遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;"}),"\n",(0,h.jsx)(n.li,{children:"单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;"}),"\n"]}),"\n",(0,h.jsxs)(n.h2,{id:"scan-基础使用",children:["scan 基础使用",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#scan-基础使用",children:"#"})]}),"\n",(0,h.jsx)(n.p,{children:"在使用之前，让我们往 Redis 里插入 10000 条数据来进行测试"}),"\n",(0,h.jsx)(n.pre,{children:(0,h.jsx)(n.code,{children:'import redis\n\nclient = redis.StrictRedis()\nfor i in range(10000):\n    client.set("key%d" % i, i)\n'})}),"\n",(0,h.jsx)(n.p,{children:"好，Redis 中现在有了 10000 条数据，接下来我们找出以 key99 开头 key 列表。"}),"\n",(0,h.jsxs)(n.p,{children:["scan 参数提供了三个参数，第一个是 ",(0,h.jsx)(n.code,{children:"cursor 整数值"}),"，第二个是 ",(0,h.jsx)(n.code,{children:"key 的正则模式"}),"，第三个是",(0,h.jsx)(n.code,{children:"遍历的 limit hint"}),"。第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束。"]}),"\n",(0,h.jsx)(n.pre,{children:(0,h.jsx)(n.code,{children:'127.0.0.1:6379> scan 0 match key99* count 1000\n1) "13976"\n2)  1) "key9911"\n    2) "key9974"\n    3) "key9994"\n    4) "key9910"\n    5) "key9907"\n    6) "key9989"\n    7) "key9971"\n    8) "key99"\n    9) "key9966"\n   10) "key992"\n   11) "key9903"\n   12) "key9905"\n127.0.0.1:6379> scan 13976 match key99* count 1000\n1) "1996"\n2)  1) "key9982"\n    2) "key9997"\n    3) "key9963"\n    4) "key996"\n    5) "key9912"\n    6) "key9999"\n    7) "key9921"\n    8) "key994"\n    9) "key9956"\n   10) "key9919"\n127.0.0.1:6379> scan 1996 match key99* count 1000\n1) "12594"\n2) 1) "key9939"\n   2) "key9941"\n   3) "key9967"\n   4) "key9938"\n   5) "key9906"\n   6) "key999"\n   7) "key9909"\n   8) "key9933"\n   9) "key9992"\n......\n127.0.0.1:6379> scan 11687 match key99* count 1000\n1) "0"\n2)  1) "key9969"\n    2) "key998"\n    3) "key9986"\n    4) "key9968"\n    5) "key9965"\n    6) "key9990"\n    7) "key9915"\n    8) "key9928"\n    9) "key9908"\n   10) "key9929"\n   11) "key9944"\n'})}),"\n",(0,h.jsx)(n.p,{children:"从上面的过程可以看到虽然提供的 limit 是 1000，但是返回的结果只有 10 个左右。因为这个 limit 不是限定返回结果的数量，而是限定服务器单次遍历的字典槽位数量(约等于)。如果将 limit 设置为 10，你会发现返回结果是空的，但是游标值不为零，意味着遍历还没结束。"}),"\n",(0,h.jsx)(n.pre,{children:(0,h.jsx)(n.code,{children:'127.0.0.1:6379> scan 0 match key99* count 10\n1) "3072"\n2) (empty list or set)\n'})}),"\n",(0,h.jsxs)(n.h2,{id:"字典的结构",children:["字典的结构",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#字典的结构",children:"#"})]}),"\n",(0,h.jsx)(n.p,{children:"在 Redis 中所有的 key 都存储在一个很大的字典中，这个字典的结构和 Java 中的 HashMap 一样，是一维数组 + 二维链表结构，第一维数组的大小总是 2^n(n>=0)，扩容一次数组大小空间加倍，也就是 n++。"}),"\n",(0,h.jsx)(n.p,{children:(0,h.jsx)(n.img,{src:"https://user-gold-cdn.xitu.io/2018/7/5/164695b9f06c757e?w=579&h=277&f=png&s=11839",alt:""})}),"\n",(0,h.jsx)(n.p,{children:"scan 指令返回的游标就是第一维数组的位置索引，我们将这个位置索引称为槽 (slot)。如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。limit 参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。"}),"\n",(0,h.jsxs)(n.h2,{id:"scan-遍历顺序",children:["scan 遍历顺序",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#scan-遍历顺序",children:"#"})]}),"\n",(0,h.jsx)(n.p,{children:"scan 的遍历顺序非常特别。它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。"}),"\n",(0,h.jsx)(n.p,{children:"首先我们用动画演示一下普通加法和高位进位加法的区别。"}),"\n",(0,h.jsx)(n.p,{children:(0,h.jsx)(n.img,{src:"https://user-gold-cdn.xitu.io/2018/7/5/16469760d12e0cbd?w=400&h=200&f=gif&s=70783",alt:""})}),"\n",(0,h.jsx)(n.p,{children:"从动画中可以看出高位进位法从左边加，进位往右边移动，同普通加法正好相反。但是最终它们都会遍历所有的槽位并且没有重复。"}),"\n",(0,h.jsxs)(n.h2,{id:"字典扩容",children:["字典扩容",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#字典扩容",children:"#"})]}),"\n",(0,h.jsx)(n.p,{children:"Java 中的 HashMap 有扩容的概念，当 loadFactor 达到阈值时，需要重新分配一个新的 2 倍大小的数组，然后将所有的元素全部 rehash 挂到新的数组下面。rehash 就是将元素的 hash 值对数组长度进行取模运算，因为长度变了，所以每个元素挂接的槽位可能也发生了变化。又因为数组的长度是 2^n 次方，所以取模运算等价于位与操作。"}),"\n",(0,h.jsx)(n.pre,{children:(0,h.jsx)(n.code,{children:"a mod 8 = a & (8-1) = a & 7\na mod 16 = a & (16-1) = a & 15\na mod 32 = a & (32-1) = a & 31\n"})}),"\n",(0,h.jsx)(n.p,{children:"这里的 7, 15, 31 称之为字典的 mask 值，mask 的作用就是保留 hash 值的低位，高位都被设置为 0。"}),"\n",(0,h.jsx)(n.p,{children:"接下来我们看看 rehash 前后元素槽位的变化。"}),"\n",(0,h.jsx)(n.p,{children:"假设当前的字典的数组长度由 8 位扩容到 16 位，那么 3 号槽位 011 将会被 rehash 到 3 号槽位和 11 号槽位，也就是说该槽位链表中大约有一半的元素还是 3 号槽位，其它的元素会放到 11 号槽位，11 这个数字的二进制是 1011，就是对 3 的二进制 011 增加了一个高位 1。"}),"\n",(0,h.jsx)(n.p,{children:(0,h.jsx)(n.img,{src:"https://user-gold-cdn.xitu.io/2018/7/5/164698cd0d3eec33?w=534&h=268&f=png&s=12978",alt:""})}),"\n",(0,h.jsx)(n.p,{children:"抽象一点说，假设开始槽位的二进制数是 xxx，那么该槽位中的元素将被 rehash 到 0xxx 和 1xxx(xxx+8) 中。\n如果字典长度由 16 位扩容到 32 位，那么对于二进制槽位 xxxx 中的元素将被 rehash 到 0xxxx 和 1xxxx(xxxx+16) 中。"}),"\n",(0,h.jsxs)(n.h2,{id:"对比扩容缩容前后的遍历顺序",children:["对比扩容缩容前后的遍历顺序",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#对比扩容缩容前后的遍历顺序",children:"#"})]}),"\n",(0,h.jsx)(n.p,{children:(0,h.jsx)(n.img,{src:"https://user-gold-cdn.xitu.io/2018/7/5/164699dae277cc19?w=1428&h=310&f=png&s=48575",alt:""})}),"\n",(0,h.jsx)(n.p,{children:"观察这张图，我们发现采用高位进位加法的遍历顺序，rehash 后的槽位在遍历顺序上是相邻的。"}),"\n",(0,h.jsx)(n.p,{children:"假设当前要即将遍历 110 这个位置 (橙色)，那么扩容后，当前槽位上所有的元素对应的新槽位是 0110 和 1110(深绿色)，也就是在槽位的二进制数增加一个高位 0 或 1。这时我们可以直接从 0110 这个槽位开始往后继续遍历，0110 槽位之前的所有槽位都是已经遍历过的，这样就可以避免扩容后对已经遍历过的槽位进行重复遍历。"}),"\n",(0,h.jsx)(n.p,{children:"再考虑缩容，假设当前即将遍历 110 这个位置 (橙色)，那么缩容后，当前槽位所有的元素对应的新槽位是 10(深绿色)，也就是去掉槽位二进制最高位。这时我们可以直接从 10 这个槽位继续往后遍历，10 槽位之前的所有槽位都是已经遍历过的，这样就可以避免缩容的重复遍历。不过缩容还是不太一样，它会对图中 010 这个槽位上的元素进行重复遍历，因为缩融后 10 槽位的元素是 010 和 110 上挂接的元素的融合。"}),"\n",(0,h.jsxs)(n.h2,{id:"渐进式-rehash",children:["渐进式 rehash",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#渐进式-rehash",children:"#"})]}),"\n",(0,h.jsxs)(n.p,{children:["Java 的 HashMap 在扩容时会一次性将旧数组下挂接的元素全部转移到新数组下面。如果 HashMap 中元素特别多，线程就会出现卡顿现象。Redis 为了解决这个问题，它采用",(0,h.jsx)(n.strong,{children:"渐进式 rehash"}),"。"]}),"\n",(0,h.jsx)(n.p,{children:"它会同时保留旧数组和新数组，然后在定时任务中以及后续对 hash 的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上。这意味着要操作处于 rehash 中的字典，需要同时访问新旧两个数组结构。如果在旧数组下面找不到元素，还需要去新数组下面去寻找。"}),"\n",(0,h.jsx)(n.p,{children:"scan 也需要考虑这个问题，对与 rehash 中的字典，它需要同时扫描新旧槽位，然后将结果融合后返回给客户端。"}),"\n",(0,h.jsxs)(n.h2,{id:"更多的-scan-指令",children:["更多的 scan 指令",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#更多的-scan-指令",children:"#"})]}),"\n",(0,h.jsx)(n.p,{children:"scan 指令是一系列指令，除了可以遍历所有的 key 之外，还可以对指定的容器集合进行遍历。比如 zscan 遍历 zset 集合元素，hscan 遍历 hash 字典的元素、sscan 遍历 set 集合的元素。"}),"\n",(0,h.jsx)(n.p,{children:"它们的原理同 scan 都会类似的，因为 hash 底层就是字典，set 也是一个特殊的 hash(所有的 value 指向同一个元素)，zset 内部也使用了字典来存储所有的元素内容，所以这里不再赘述。"}),"\n",(0,h.jsxs)(n.h2,{id:"大-key-扫描",children:["大 key 扫描",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#大-key-扫描",children:"#"})]}),"\n",(0,h.jsx)(n.p,{children:"有时候会因为业务人员使用不当，在 Redis 实例中会形成很大的对象，比如一个很大的 hash，一个很大的 zset 这都是经常出现的。这样的对象对 Redis 的集群数据迁移带来了很大的问题，因为在集群环境下，如果某个 key 太大，会数据导致迁移卡顿。另外在内存分配上，如果一个 key 太大，那么当它需要扩容时，会一次性申请更大的一块内存，这也会导致卡顿。如果这个大 key 被删除，内存会一次性回收，卡顿现象会再一次产生。"}),"\n",(0,h.jsxs)(n.p,{children:[(0,h.jsx)(n.strong,{children:"在平时的业务开发中，要尽量避免大 key 的产生"}),"。"]}),"\n",(0,h.jsx)(n.p,{children:"如果你观察到 Redis 的内存大起大落，这极有可能是因为大 key 导致的，这时候你就需要定位出具体是那个 key，进一步定位出具体的业务来源，然后再改进相关业务代码设计。"}),"\n",(0,h.jsx)(n.p,{children:(0,h.jsx)(n.strong,{children:"那如何定位大 key 呢？"})}),"\n",(0,h.jsx)(n.p,{children:"为了避免对线上 Redis 带来卡顿，这就要用到 scan 指令，对于扫描出来的每一个 key，使用 type 指令获得 key 的类型，然后使用相应数据结构的 size 或者 len 方法来得到它的大小，对于每一种类型，保留大小的前 N 名作为扫描结果展示出来。"}),"\n",(0,h.jsx)(n.p,{children:"上面这样的过程需要编写脚本，比较繁琐，不过 Redis 官方已经在 redis-cli 指令中提供了这样的扫描功能，我们可以直接拿来即用。"}),"\n",(0,h.jsx)(n.pre,{children:(0,h.jsx)(n.code,{children:"redis-cli -h 127.0.0.1 -p 7001 –-bigkeys\n"})}),"\n",(0,h.jsx)(n.p,{children:"如果你担心这个指令会大幅抬升 Redis 的 ops 导致线上报警，还可以增加一个休眠参数。"}),"\n",(0,h.jsx)(n.pre,{children:(0,h.jsx)(n.code,{children:"redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1\n"})}),"\n",(0,h.jsx)(n.p,{children:"上面这个指令每隔 100 条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的时间会变长。"}),"\n",(0,h.jsxs)(n.h2,{id:"扩展阅读",children:["扩展阅读",(0,h.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#扩展阅读",children:"#"})]}),"\n",(0,h.jsxs)(n.p,{children:["感兴趣可以继续深入阅读 ",(0,h.jsx)(n.a,{href:"https://mp.weixin.qq.com/s/ufoLJiXE0wU4Bc7ZbE9cDQ",target:"_blank",rel:"noopener noreferrer",children:"美团近期修复的Scan的一个bug"})]})]})}function i(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,c.ah)(),e.components);return n?(0,h.jsx)(n,{...e,children:(0,h.jsx)(d,{...e})}):d(e)}let r=i;i.__RSPRESS_PAGE_META={},i.__RSPRESS_PAGE_META["Redis%20%E6%B7%B1%E5%BA%A6%E5%8E%86%E9%99%A9%EF%BC%9A%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%2F10%E5%BA%94%E7%94%A8%209%EF%BC%9A%E5%A4%A7%E6%B5%B7%E6%8D%9E%E9%92%88%20%E2%80%94%E2%80%94%20Scan.md"]={toc:[{text:"scan 基础使用",id:"scan-基础使用",depth:2},{text:"字典的结构",id:"字典的结构",depth:2},{text:"scan 遍历顺序",id:"scan-遍历顺序",depth:2},{text:"字典扩容",id:"字典扩容",depth:2},{text:"对比扩容缩容前后的遍历顺序",id:"对比扩容缩容前后的遍历顺序",depth:2},{text:"渐进式 rehash",id:"渐进式-rehash",depth:2},{text:"更多的 scan 指令",id:"更多的-scan-指令",depth:2},{text:"大 key 扫描",id:"大-key-扫描",depth:2},{text:"扩展阅读",id:"扩展阅读",depth:2}],title:"10应用 9：大海捞针 —— Scan",headingTitle:"10应用 9：大海捞针 —— Scan",frontmatter:{}}}}]);