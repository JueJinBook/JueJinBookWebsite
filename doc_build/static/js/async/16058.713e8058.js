"use strict";(self.webpackChunkjue_jin_book_press=self.webpackChunkjue_jin_book_press||[]).push([["16058"],{22196:function(e,n,r){r.r(n),r.d(n,{default:()=>l});var s=r(552676),t=r(740453);function c(e){let n=Object.assign({h3:"h3",a:"a",h1:"h1",pre:"pre",code:"code",p:"p",h5:"h5"},(0,t.ah)(),e.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h3,{id:"",children:(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#",children:"#"})}),"\n",(0,s.jsxs)(n.h1,{id:"11案例十-压测-cluster-的并发负载-node-的集群---cluster",children:["11案例十： [压测 Cluster 的并发负载] Node 的集群 - cluster",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#11案例十-压测-cluster-的并发负载-node-的集群---cluster",children:"#"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-!",children:"本节目标：【压测 cluster 的集群负载能力】 - 所谓双拳难敌四手，cluster 的集群扩展可以分摊利用多核，健壮可扩展有了可能。\n"})}),"\n",(0,s.jsx)(n.p,{children:"我们都知道 Node 是事件驱动的异步服务模型，高效的同时也很脆弱，因为所有的事情都是在一个单线程中完成的，一旦这个单线程挂了，那么整个服务就挂了，或者有点这个单线程里有个非常耗时的同步任务，那么其他的请求进来也会阻滞在这里了，这时候我们就希望能充分利用计算机的多核优势，多起几个独立的进程，每个进程都像是伏地魔的一个魂，让我们的服务有多条命，就算是一个挂了，整个服务还不至于瘫痪，而且还可以把压力分摊到每个进程上面，整体服务更加健壮，也能支撑更多的并发。"}),"\n",(0,s.jsxs)(n.p,{children:["幸运的是，在 Node 里面，提供 ",(0,s.jsx)(n.code,{children:"cluster"})," 这个模块，来实现服务集群的扩展，具体怎么用呢，我们先起一个简单的服务器来返回一段文本，同时里面放一个略大的数组来阻滞下代码运行。"]}),"\n",(0,s.jsxs)(n.h3,{id:"起一个简单的-http-server",children:["起一个简单的 HTTP Server",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#起一个简单的-http-server",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"先来实现一个略微耗时的任务："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const t1 = Date.now()\n// 来用一个 1 百万长度的数组来模拟耗时操作\nfor (var i = 0; i < 1000000; i++) {}\nconst t2 = Date.now()\n// 最后打印下耗时操作用时\nconsole.log('耗时', t2 - t1, '毫秒')\n"})}),"\n",(0,s.jsxs)(n.p,{children:["我的电脑打印后是这样的结果：",(0,s.jsx)(n.code,{children:"耗时 3 毫秒"})]}),"\n",(0,s.jsx)(n.p,{children:"然后我们起一个 Server，把任务丢进去作为响应返回："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// 通过 http 创建创建一个服务器实例\nrequire('http').createServer((req, res) => {\n  for (var i = 0; i < 1000000; i++) {}\n  // 返回一段文本\n  res.statusCode = 200\n  res.setHeader('Content-Type', 'text/plain')\n  res.end('经过一个耗时操作，这是返回的一段文本\\n')\n}).listen(5000, '127.0.0.1', () => console.log('服务启动了'))\n"})}),"\n",(0,s.jsxs)(n.p,{children:["在命令行 ",(0,s.jsx)(n.code,{children:"node server.js"})," 服务开起来后，我们压测一下，压测的话，大家可以使用 ",(0,s.jsx)(n.a,{href:"http://httpd.apache.org/docs/2.2/programs/ab.html",target:"_blank",rel:"noopener noreferrer",children:"Apache ab"}),"、",(0,s.jsx)(n.a,{href:"https://www.joedog.org/siege-home/",target:"_blank",rel:"noopener noreferrer",children:"siege"}),"、",(0,s.jsx)(n.a,{href:"https://github.com/wg/wrk",target:"_blank",rel:"noopener noreferrer",children:"wrk"})," 等等，具体教程大家参考官方文档，我们这里使用一个 Node 的简单压测工具 ",(0,s.jsx)(n.a,{href:"https://github.com/mcollina/autocannon",target:"_blank",rel:"noopener noreferrer",children:"autocannon"}),"，首先把它安装到本地："]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# 安装 autocannon 到全局\nnpm i autocannon -g\n"})}),"\n",(0,s.jsx)(n.p,{children:"安装后，通过 node server.js 开启服务，同时再开一个命令行窗口，输入下面命令运行："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"autocannon -c 1000 -p 10 http://127.0.0.1:5000\n"})}),"\n",(0,s.jsx)(n.p,{children:"这些参数意思是："}),"\n",(0,s.jsx)(n.p,{children:"-c 是并发连接的数量，默认 10，我们指定为 1000\n-p 指定每个连接的流水线请求数，默认是 1，我们指定为 10"}),"\n",(0,s.jsx)(n.p,{children:"在我电脑上我压测了 3 次，结果如下："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"➜  ~ autocannon -c 1000 -p 10 http://127.0.0.1:5000\nRunning 10s test @ http://127.0.0.1:5000\n1000 connections with 10 pipelining factor\n# A 接口的延迟程度\nStat    2.5% 50%  97.5%   99%     Avg       Stdev      Max\nLatency 0 ms 0 ms 4061 ms 4652 ms 368.29 ms 1248.24 ms 9176.69 ms\n# B 每秒能处理的请求数 TPS\nStat      1%     2.5%   50%    97.5%  Avg    Stdev   Min\nReq/Sec   1591   1591   1918   1940   1888.1 101.11  1591\n# C 每秒返回的字节数\nBytes/Sec 288 kB 288 kB 347 kB 351 kB 342 kB 18.3 kB 288 kB\n\n19k requests in 10.15s, 3.42 MB read\n760 errors (730 timeouts)\n\n➜  ~ autocannon -c 1000 -p 10 http://127.0.0.1:5000\nStat    2.5% 50%  97.5%   99%     Avg       Stdev      Max\nLatency 0 ms 0 ms 4895 ms 4908 ms 373.95 ms 1226.24 ms 5582.86 ms\nStat      1%     2.5%   50%    97.5%  Avg    Stdev   Min\nReq/Sec   1641   1641   1910   1970   1872.1 112.94  1641\nBytes/Sec 297 kB 297 kB 346 kB 357 kB 339 kB 20.4 kB 297 kB\n19k requests in 10.16s, 3.39 MB read\n875 errors (870 timeouts)\n\n➜  ~ autocannon -c 1000 -p 10 http://127.0.0.1:5000\nStat    2.5% 50%  97.5%   99%     Avg       Stdev      Max\nLatency 0 ms 0 ms 4729 ms 4748 ms 370.43 ms 1208.29 ms 5539.08 ms\nStat      1%     2.5%   50%    97.5%  Avg    Stdev   Min\nReq/Sec   1631   1631   1961   1980   1928.1 101.4   1631\nBytes/Sec 295 kB 295 kB 355 kB 358 kB 349 kB 18.3 kB 295 kB\n19k requests in 10.14s, 3.49 MB read\n600 errors (590 timeouts)\n"})}),"\n",(0,s.jsx)(n.p,{children:"压测的指标分为三部分，也就是 ABC，延迟越低，TPS 越高，每秒返回的字节数越多，就说明服务的响应能力越好，性能越好。"}),"\n",(0,s.jsx)(n.p,{children:"压测的结果不太稳定，但大体上可以看到，我们单核跑这个服务时候，延迟 4 秒多才能有返回，同时每秒处理的请求个数有 2 千上下，能吞吐响应的字节数，在二三百 KB 之内徘徊，在 10 秒内能响应的请求数有 2 万左右，同时还伴随有几百个超时错误，这样的结果不是太理想，我们改用 cluster 起服务下看看效果。"}),"\n",(0,s.jsxs)(n.h3,{id:"通过-cluster-启动-http-服务",children:["通过 cluster 启动 HTTP 服务",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#通过-cluster-启动-http-服务",children:"#"})]}),"\n",(0,s.jsxs)(n.p,{children:["Node cluster 的用法非常简单，启动服务文件的时候，判断是否是 Master 模式，如果是则直接调用 ",(0,s.jsx)(n.code,{children:"cluster fork"})," 来创建多个服务实例，如果不是 Master，就直接启动一个服务器实例，我们稍后再来了解这些概念，先看下被 cluster 优化后的代码："]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const http = require('http')\n// 加载拿到 cluster 模块\nconst cluster = require('cluster')\n// 通过 os 模块拿到当前计算机上的 cpu\nconst cpus = require('os').cpus()\n\n// cluster 能拿到当前是否是 master 模式\nif (cluster.isMaster) {\n  // master 下，对每个 cpu 都 fork 一个进程\n  // 相当于是把 cpu 个数都吃满，充分利用多核优势\n  for (let i = 0; i < cpus.length; i ++) {\n    cluster.fork()\n  }\n} else {\n  // 如果不是 master 模式，则每个子进程都会启动这个服务\n  // 相当于有多少个 cpu，fork 了多少个进程，这里就会有多少个服务器\n  http.Server((req, res) => {\n    for (var i = 0; i < 1000000; i++) {}\n    res.statusCode = 200\n    res.setHeader('Content-Type', 'text/plain')\n    res.end('经过一个耗时操作，这是返回的一段文本\\n')\n  }).listen(5000, () => console.log('服务启动了'))\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["然后依然在命令行窗口中执行 ",(0,s.jsx)(n.code,{children:"node server.js"}),"，然后新开一个窗口，进行压测："]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"➜  ~ autocannon -c 1000 -p 10 http://127.0.0.1:5000\nStat    2.5% 50%  97.5%   99%     Avg       Stdev    Max\nLatency 0 ms 0 ms 1132 ms 1164 ms 101.92 ms 354.6 ms 9963.98 ms\nStat      1%      2.5%    50%     97.5%   Avg    Stdev   Min\nReq/Sec   6371    6371    7263    7383    7187.6 286.23  6368\nBytes/Sec 1.15 MB 1.15 MB 1.31 MB 1.34 MB 1.3 MB 51.9 kB 1.15 MB\n72k requests in 10.17s, 13 MB read\n640 errors (640 timeouts)\n\n➜  ~ autocannon -c 1000 -p 10 http://127.0.0.1:5000\nStat    2.5% 50%  97.5%   99%     Avg      Stdev     Max\nLatency 0 ms 0 ms 1195 ms 1274 ms 113.6 ms 376.96 ms 9984.54 ms\nStat      1%      2.5%    50%     97.5%   Avg     Stdev   Min\nReq/Sec   6459    6459    7391    7471    7294.4  284.22  6457\nBytes/Sec 1.17 MB 1.17 MB 1.34 MB 1.35 MB 1.32 MB 51.4 kB 1.17 MB\n73k requests in 10.17s, 13.2 MB read\n560 errors (560 timeouts)\n\n➜  ~ autocannon -c 1000 -p 10 http://127.0.0.1:5000\nStat    2.5% 50%  97.5%   99%     Avg       Stdev     Max\nLatency 0 ms 0 ms 1355 ms 1443 ms 119.83 ms 396.95 ms 9926.91 ms\nStat      1%      2.5%    50%     97.5%   Avg    Stdev   Min\nReq/Sec   6359    6359    7259    7371    7176.8 280.34  6358\nBytes/Sec 1.15 MB 1.15 MB 1.31 MB 1.33 MB 1.3 MB 50.9 kB 1.15 MB\n72k requests in 10.19s, 13 MB read\n800 errors (800 timeouts)\n"})}),"\n",(0,s.jsx)(n.p,{children:"同样压测了 3 次，发现超时错误的次数依然是几百个，但是服务的整体响应能力，从 10 秒响应的 2 万个，增长到了 7 万多个，翻了 3 倍多，同时延迟时间也从 4 秒降到了 1 秒多，每秒的处理次数也从 2 千增长到了 7 千，响应的字节数从二三百 KB 增长到了 1 MB 多，整体的服务性能改善还是非常可观的，这就是 Node cluster 带给我们的收益，想想还是很激动的。"}),"\n",(0,s.jsxs)(n.h3,{id:"关于-cluster",children:["关于 cluster",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#关于-cluster",children:"#"})]}),"\n",(0,s.jsxs)(n.p,{children:["在刚才的测试里面，起到关键作用的一句代码就是 ",(0,s.jsx)(n.code,{children:"cluster.fork()"}),"，通过 fork 按照 cpu 的个数，创建了多个子进程，也就是 child process，我们管它叫 worker，这些 worker 会共享同一个服务器端口，也就是 server port，而能做到这一点离不开主进程的调度，也就是 master process。"]}),"\n",(0,s.jsx)(n.p,{children:"对于 cluster 模块，它里面有几个事件，其中比较常见的一个是 online 事件，当 worker 被 fork 出来发送 online message，而 exit 会在一个 worker 进程杀掉挂掉的时候会被触发，我们来一段代码感受一下："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const cluster = require('cluster')\nconst http = require('http')\n\n// 通过 if else 区分下主进程和子进程各自的启动逻辑\nif (cluster.isMaster) masterProcess()\nelse childProcess()\n\nfunction masterProcess () {\n  // 可以选择只启动 2 个 worker\n  for (let i = 0; i < 2; i ++) {\n    let worker = cluster.fork()\n  }\n\n  // 进程创建成功 则触发 online 事件\n  cluster.on('online', worker => {\n    console.log('子进程 ' + worker.process.pid + ' 创建成功')\n  })\n\n  // 进程退出 则触发 exit 事件\n  cluster.on('exit', (worker, code, signal) => {\n    console.log(`子进程 ${worker.process.pid} 退出`)\n  })\n}\n\nfunction childProcess () {\n  console.log(`子进程开始 ${process.pid} 开始启动服务器...`)\n\n  http.Server((req, res) => {\n    res.statusCode = 200\n    res.setHeader('Content-Type', 'text/plain')\n    console.log('来自子进程 id 为 ' + cluster.worker.id + ' 的响应')\n    res.end('Hello Juejin!')\n    process.exit(1)\n  }).listen(5000, () => {\n    console.log('子进程 ' + process.pid + ' 已成功监听 5000 端口')\n  })\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"当我们访问服务的时候，可以拿到返回的 Hello Juejin，但同时服务器也退出了，退出的时候，自然 cluster 启动的子进程也会退出，所以打印了如下的这段日志："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"~ curl http://127.0.0.1:5000\n\n子进程 16725 创建成功\n子进程 16726 创建成功\n子进程开始 16726 开始启动服务器...\n子进程开始 16725 开始启动服务器...\n子进程 16726 已成功监听 5000 端口\n子进程 16725 已成功监听 5000 端口\n来自子进程 id 为 2 的响应\n子进程 16726 退出\n# 访问浏览器 http://127.0.0.1:5000 可能会多出一个响应\n来自子进程 id 为 1 的响应\n子进程 16725 退出\n"})}),"\n",(0,s.jsx)(n.p,{children:"浏览器请求的时候，可能会多发一个 favicon 的请求，等于是两个请求，第一个子进程退出后，第二个子进程会接管之后而来的其他请求，响应后也会退出，所以会多打印两行日志。"}),"\n",(0,s.jsxs)(n.p,{children:["那 worker 负责干活，master 呢？master 在这里的作用，就是启动多个 worker，然后来调度这些 worker，然后在主进程和子进程之间通过 IPC 实现进程间的通信，但是子进程之间的任务怎么分配呢？ 我们上面的代码案例中，如果把 ",(0,s.jsx)(n.code,{children:"process.exit(1)"})," 拿掉后，然后不断的刷新浏览器，会发现实际上真正干活的子进程，一会是 1 一会是 2，并没有什么明显的规律，只是看上去大概符合 1：1 的平均分配，这里的分配就是 cluster 底层做的，用的调度算法是 RR 算法，也就是 Round-Robin 算法，调用的地方在 ",(0,s.jsx)(n.code,{children:"lib/internal/cluster/child.js"})," 源码 ",(0,s.jsx)(n.a,{href:"https://github.com/nodejs/node/blob/v10.x/lib/internal/cluster/child.js#L93",target:"_blank",rel:"noopener noreferrer",children:"93 行 cluster._getServer"})," 这里："]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"cluster._getServer = function(obj, options, cb) {\n  let address = options.address;\n\n  // Resolve unix socket paths to absolute paths\n  address = path.resolve(address);\n\n  const indexesKey = [address,\n                      options.port,\n                      options.addressType,\n                      options.fd ].join(':');\n\n  if (indexes[indexesKey] === undefined)\n    indexes[indexesKey] = 0;\n  else\n    indexes[indexesKey]++;\n\n  const message = util._extend({\n    act: 'queryServer',\n    index: indexes[indexesKey],\n    data: null\n  }, options);\n\n  message.address = address;\n\n  if (obj._getServerData)\n    message.data = obj._getServerData();\n\n  send(message, (reply, handle) => {\n    if (typeof obj._setServerData === 'function')\n      obj._setServerData(reply.data);\n\n    if (handle)\n      shared(reply, handle, indexesKey, cb);  // Shared listen socket.\n    else\n      rr(reply, indexesKey, cb); // Round-robin.\n  });\n\n  obj.once('listening', () => {\n    cluster.worker.state = 'listening';\n    const address = obj.address();\n    message.act = 'listening';\n    message.port = address && address.port || options.port;\n    send(message);\n  });\n};\n"})}),"\n",(0,s.jsxs)(n.h3,{id:"cluster-如果挂了怎么办",children:["cluster 如果挂了怎么办",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#cluster-如果挂了怎么办",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"我们上面代码案例中通过 process.exit 来退出程序了，如果是其他异常导致子进程异常呢，来看如下代码："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const cluster = require('cluster')\nconst http = require('http')\n\nif (cluster.isMaster) masterProcess()\nelse childProcess()\n\nfunction masterProcess () {\n  // 只启动 1 个 worker\n  const worker = cluster.fork()\n  cluster.on('exit', (worker, code, signal) => {\n    console.log(`子进程 ${worker.process.pid} 挂了`)\n  })\n}\n\nfunction childProcess () {\n  http.Server((req, res) => {\n    console.log('子进程 ' + cluster.worker.id + ' 在响应')\n    // 此处发生异常\n    throw new Error({})\n    res.end('Hello Juejin!')\n  }).listen(5000, () => {\n    console.log('子进程 ' + process.pid + ' 监听中')\n  })\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["我们访问 ",(0,s.jsx)(n.code,{children:"http://127.0.0.1:5000"}),"，会看到如下的服务报错："]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"子进程 20739 监听中\n子进程 1 在响应\n/Users/black/Downloads/node-10.x/juejin/server.js:18\n    throw new Error({})\n    ^\nError: [object Object]\n    at Server.http.Server (/Users/black/Downloads/node-10.x/juejin/server.js:18:11)\n    at Server.emit (events.js:182:13)\n    at parserOnIncoming (_http_server.js:652:12)\n    at HTTPParser.parserOnHeadersComplete (_http_common.js:109:17)\n子进程 20739 挂了\n"})}),"\n",(0,s.jsx)(n.p,{children:"可以看到，能通过 cluster 的 exit 事件监听到子进程挂掉，那么我们就可以在 exit 的时候，再启动一个进程，改下代码成这样子："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const cluster = require('cluster')\nconst http = require('http')\n\nif (cluster.isMaster) masterProcess()\nelse childProcess()\n\nfunction masterProcess () {\n  // 只启动 1 个 worker\n  cluster.fork()\n  cluster.on('exit', (worker, code, signal) => {\n    console.log(`子进程 ${worker.process.pid} 挂了`)\n    if (code != 0 && !worker.suicide) {\n      cluster.fork()\n      console.log('再启动一个新的子进程')\n    }\n  })\n}\n\nfunction childProcess () {\n  http.Server((req, res) => {\n    console.log('子进程 ' + cluster.worker.id + ' 在响应')\n    throw new Error({})\n    res.end('Hello Juejin!')\n  }).listen(5000, () => {\n    console.log('子进程 ' + process.pid + ' 监听中')\n  })\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"同样的请求后，我们观察终端打印的日志如下："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"子进程 20956 监听中\n子进程 1 在响应\n/Users/black/Downloads/node-10.x/juejin/server.js:22\n    throw new Error({})\n    ^\nError: [object Object]\n    at Server.http.Server (/Users/black/Downloads/node-10.x/juejin/server.js:22:11)\n    at Server.emit (events.js:182:13)\n    at parserOnIncoming (_http_server.js:652:12)\n    at HTTPParser.parserOnHeadersComplete (_http_common.js:109:17)\n子进程 20956 挂了\n再启动一个新的子进程\n子进程 20960 监听中\n"})}),"\n",(0,s.jsx)(n.p,{children:"看到虽然子进程 20956 挂了，但是 子进程 20960 已经跑起来，可以继续接管后续的请求了。"}),"\n",(0,s.jsxs)(n.h3,{id:"有哪些能实现横向扩展-cluster-的工具",children:["有哪些能实现横向扩展 cluster 的工具",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#有哪些能实现横向扩展-cluster-的工具",children:"#"})]}),"\n",(0,s.jsxs)(n.p,{children:["虽然我们知道 cluster 的大概原理，但人肉来维护进程显然不是我们在学习 Node 初期可以深度掌握的技能，需要一些工具的配合，那么这里就给大家推荐两个工具，一个是 ",(0,s.jsx)(n.a,{href:"https://github.com/Unitech/pm2",target:"_blank",rel:"noopener noreferrer",children:"pm2"}),"，一个是阿里的 Egg 框架自带的 egg-cluster，关于后者我们本册先不涉及，先来看下 pm2。"]}),"\n",(0,s.jsx)(n.p,{children:"pm2 的安装特别简单："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# 安装到全局\nnpm i pm2 -g\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://pm2.io/doc",target:"_blank",rel:"noopener noreferrer",children:"pm2 官方文档"}),"也特别详尽，大家可以前往学习，我挑几个自己常用的介绍下。"]}),"\n",(0,s.jsxs)(n.h5,{id:"pm2-启动服务器",children:["pm2 启动服务器",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#pm2-启动服务器",children:"#"})]}),"\n",(0,s.jsxs)(n.p,{children:["推荐大家从配置文件启动，配置文件参考",(0,s.jsx)(n.a,{href:"https://pm2.io/doc/en/runtime/guide/ecosystem-file/",target:"_blank",rel:"noopener noreferrer",children:"官网"}),"，从命令行启动非常简单："]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pm2 start app.js -i 2\n"})}),"\n",(0,s.jsxs)(n.p,{children:["-i 后面跟的 2 表示启动 2 个 server 实例，如果输入 0 的话，则按照当前服务器它实际的 cpu 核数来启动多个 server，启动后，我们通过 ",(0,s.jsx)(n.code,{children:"pm2 ls 来看看已经启动的实例"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"~ pm2 ls\n┌────┬──┬────┬───────┬──────┬───┬──────┬───────┐\n│Name│id│mode│status │↺     │cpu│memory│       │\n├────┼──┼────┼───────┼──────┼───┼──────┼───────┤\n│app │0 │N/A │cluster│online│0  │19%   │28.4 MB│\n│app │1 │N/A │cluster│online│0  │0%    │20.3 MB│\n└────┴──┴────┴───────┴──────┴───┴──────┴───────┘\n"})}),"\n",(0,s.jsxs)(n.h5,{id:"pm2-实时扩容集群",children:["pm2 实时扩容集群",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#pm2-实时扩容集群",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"如果我们发现线上的服务响应比较吃力，而 cpu 核数没有吃满的话，我们可以实时扩容集群，通过 scale 命令来实现："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"pm2 scale app +1\n[PM2] Scaling up application\n┌─────┬──┬────┬───────┬──────┬───┬──────┬───────┐\n│ Name│id│mode│status │↺     │cpu│memory│       │\n├─────┼──┼────┼───────┼──────┼───┼──────┼───────┤\n│ app │0 │N/A │cluster│online│0  │0%    │33.6 MB│\n│ app │1 │N/A │cluster│online│0  │0%    │34.2 MB│\n│ app │2 │N/A │cluster│online│0  │0%    │19.9 MB│\n└─────┴──┴────┴───────┴──────┴───┴──────┴───────┘\n"})}),"\n",(0,s.jsx)(n.p,{children:"这里的 +1 就是扩容一个服务实例，其实就是增加一个 cluster 的 worker 子进程，扩容后："}),"\n",(0,s.jsxs)(n.h5,{id:"pm2-终止某个进程",children:["pm2 终止某个进程",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#pm2-终止某个进程",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"有时候如果某个进程明显卡住了，或者线上负载不大，可以杀掉部分进程，通过："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"e12-cluster git:(master) ✗ pm2 stop 1\n[PM2] Applying action stopProcessId on app [1](ids: 1)\n[PM2] [app](1) ✓\n┌────┬──┬────┬───────┬───────┬───┬──────┬───────┐\n│Name│id│mode│status │↺      │cpu│memory│       │\n├────┼──┼────┼───────┼───────┼───┼──────┼───────┤\n│app │0 │N/A │cluster│online │0  │0%    │33.6 MB│\n│app │1 │N/A │cluster│stopped│0  │0%    │0 B    │\n│app │2 │N/A │cluster│online │0  │0%    │33.6 MB│\n└────┴──┴────┴───────┴───────┴───┴──────┴───────┘\n"})}),"\n",(0,s.jsx)(n.p,{children:"可以看到进程 ID 为 2 的 worker 已经是 stopped 状态。"}),"\n",(0,s.jsxs)(n.h5,{id:"pm2-平滑重启进程",children:["pm2 平滑重启进程",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#pm2-平滑重启进程",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"有时候，如果想要某个比较吃内存的进程可以重启，或者想要所有的 worder 都重新启动，但是又希望不影响进程正常处理用户的请求，可以使用 pm2 的 gracefulReload 命令："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"➜ pm2 reload app\nUse --update-env to update environment variables\n[PM2] Applying action reloadProcessId on app [app](ids: 0,1,2)\n[PM2] [app](1) ✓\n[PM2] [app](0) ✓\n[PM2] [app](2) ✓\n➜ pm2 ls\n┌────┬──┬────┬───────┬──────┬───┬──────┬───────┐\n│Name│id│mode│status │↺     │cpu│memory│       │ \n├────┼──┼────┼───────┼──────┼───┼──────┼───────┤\n│app │0 │N/A │cluster│online│1  │6.8%  │37.4 MB│\n│app │1 │N/A │cluster│online│0  │6.8%  │37.4 MB│\n│app │2 │N/A │cluster│online│1  │6.4%  │37.5 MB│\n└────┴──┴────┴───────┴──────┴───┴──────┴───────┘\n"})}),"\n",(0,s.jsx)(n.p,{children:"这样所有的子进程又原地满血复活，当然也会存在说，某些进程上面的未处理连接或者任务的确很重，比如有一些大而重的文件 IO 或者数据库 IO 在等待，会导致 reload 失败，这时候也可以指定一个超时时间，命令会退化到 restart 模式，强制杀死进程再重启，或者我们可以在代码中再友好一些，当它收到 pm2 要重启的时候，在程序里面我们把一些任务清空掉然后让服务重启："}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// pm2 会发出 SIGINT 事件，我们监听事件\nprocess.on('SIGINT', function() {\n // 处理一些任务然后再信号交还给 PM2 来重启服务\n db.stop(function(err) {\n  process.exit(err ? 1 : 0)\n })\n})\n"})}),"\n",(0,s.jsxs)(n.h3,{id:"小结",children:["小结",(0,s.jsx)(n.a,{className:"header-anchor","aria-hidden":"true",href:"#小结",children:"#"})]}),"\n",(0,s.jsx)(n.p,{children:"简单总结一下，我们现在了解到 cluster 可以分摊服务器的压力，可以最大的利用多核 CPU 的资源，从而实现并发和整体响应性能的提升，同时在服务的健壮性上，我们也可以通过监听子进程的异常来杀死或者启动一个新的子进程，从而实现了多进程多服务的有效负载。我们在生产环境中，也可以通过 pm2 这样的部署运维工具，来保持服务的自动重启和更简便的集群扩展，甚至可以使用它的高级功能如监控等等，对于一些不太复杂的系统我们就有这样的配套全家桶了。"})]})}function a(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,t.ah)(),e.components);return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}let l=a;a.__RSPRESS_PAGE_META={},a.__RSPRESS_PAGE_META["%E4%BB%A3%E7%A0%81%E6%A1%88%E4%BE%8B%E6%8E%8C%E6%8F%A1%20NodeJS%20%E6%A0%B8%E5%BF%83%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F11%E6%A1%88%E4%BE%8B%E5%8D%81%EF%BC%9A%20%5B%E5%8E%8B%E6%B5%8B%20Cluster%20%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B4%9F%E8%BD%BD%5D%20Node%20%E7%9A%84%E9%9B%86%E7%BE%A4%20-%20cluster.md"]={toc:[{text:"",id:"",depth:3},{text:"起一个简单的 HTTP Server",id:"起一个简单的-http-server",depth:3},{text:"通过 cluster 启动 HTTP 服务",id:"通过-cluster-启动-http-服务",depth:3},{text:"关于 cluster",id:"关于-cluster",depth:3},{text:"cluster 如果挂了怎么办",id:"cluster-如果挂了怎么办",depth:3},{text:"有哪些能实现横向扩展 cluster 的工具",id:"有哪些能实现横向扩展-cluster-的工具",depth:3},{text:"小结",id:"小结",depth:3}],title:"11案例十： [压测 Cluster 的并发负载] Node 的集群 - cluster",headingTitle:"11案例十： [压测 Cluster 的并发负载] Node 的集群 - cluster",frontmatter:{}}}}]);