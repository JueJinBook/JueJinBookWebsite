"use strict";(self.webpackChunkjue_jin_book_press=self.webpackChunkjue_jin_book_press||[]).push([["25359"],{881832:function(n,e,t){t.r(e),t.d(e,{default:()=>l});var s=t(552676),c=t(740453);function o(n){let e=Object.assign({h1:"h1",a:"a",blockquote:"blockquote",p:"p",pre:"pre",code:"code",ul:"ul",li:"li",h2:"h2"},(0,c.ah)(),n.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(e.h1,{id:"17-function-calling使用-llm-去调用外界-api",children:["17-Function Calling：使用 LLM 去调用外界 API",(0,s.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#17-function-calling使用-llm-去调用外界-api",children:"#"})]}),"\n",(0,s.jsxs)(e.blockquote,{children:["\n",(0,s.jsxs)(e.p,{children:["本章对应源代码：",(0,s.jsx)(e.a,{href:"https://github.com/RealKai42/langchainjs-juejin/blob/main/tool-lesson.ipynb",target:"_blank",rel:"noopener noreferrer",children:"https://github.com/RealKai42/langchainjs-juejin/blob/main/tool-lesson.ipynb"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"在新的一章的开始，让我们了解构建一切 AI Agent 的基础 -- 「Function calling 」。"}),"\n",(0,s.jsx)(e.p,{children:"Function calling 本质上就是给 LLM 了解和调用外界函数的能力，LLM 会根据他的理解，在合适的时间返回对函数的调用和参数，然后根据函数调用的结果进行回答。例如，你在构建一个旅游计划的 chatbot，用户给出问题 “规划一个 2.11 日北京的旅游行程，帮我选择最合适天气的衣服”，LLM 就会判断需要调用获取 2.11 实时天气的 API 来获取北京在 2.11 的天气，并根据返回的结果来回答问题。"}),"\n",(0,s.jsx)(e.p,{children:"本节中，我们先把 langchain 放一放，先使用 OpenAI 官方 API 去尝试理解和使用 function calling API。\n注意，后续 OpenAI 将 function calling 更名成了 tools，但目前很多资料依旧叫 function calling， 我感觉这个名称也更贴合这个 API 的本意，但我们还是尽量紧跟最新的标准，后续都会以 tools 称呼这个 API。"}),"\n",(0,s.jsx)(e.p,{children:"Tools 基本使用\n获取天气是非常经典的使用案例，这个需要实时获取外部 API 的结果，LLM 无法独立回答。这里我们使用 OpenAI 官方库，首先引入并初始化"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'import OpenAI from "openai";\n\nconst openai = new OpenAI({\n    apiKey: env["API_KEY"],\n});\n'})}),"\n",(0,s.jsx)(e.p,{children:"然后我们创建一个假的获取天气的函数"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'function getCurrentWeather({ location, unit="fahrenheit"}){\n   const  weather_info = {\n        "location": location,\n        "temperature": "72",\n        "unit": unit,\n        "forecast": ["sunny", "windy"],\n    }\n    return JSON.stringify(weather_info);\n}\n'})}),"\n",(0,s.jsx)(e.p,{children:"然后我们创建这个函数的描述信息"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'const tools = [\n    {\n      type: "function",\n      function: {\n        name: "getCurrentWeather",\n        description: "Get the current weather in a given location",\n        parameters: {\n          type: "object",\n          properties: {\n            location: {\n              type: "string",\n              description: "The city and state, e.g. San Francisco, CA",\n            },\n            unit: { type: "string", enum: ["celsius", "fahrenheit"] },\n          },\n          required: ["location"],\n        },\n      },\n    }\n]\n'})}),"\n",(0,s.jsx)(e.p,{children:"这里是 OpenAI 官方 API 指定的格式，我们逐步解析这里的定义，"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:'type: "function"'})," 目前只支持值为 function, 必须指定"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"function"})," 是对具体函数的描述"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"name"})," 是函数名, 需要跟函数的名称一致, 方便我们后续实现对函数名的调用"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"descirption"})," 函数的描述, 你可以理解成对 LLM 决定什么是否调用该函数的唯一信息, 这部分清晰的表达函数的效果"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"parameters"})," 函数的参数, OpenAI 使用的是通用的 JSON Schema 去描述函数的各个参数, 在我们这里使用了数组作为参数的输入, 其中有两个 key\n - ",(0,s.jsx)(e.code,{children:"location"})," 一个 string 值表示位置\n - ",(0,s.jsx)(e.code,{children:"unit"})," 表示请求的单位"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"required"})," 通过这个 key 告知 LLM 该参数是必须的"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"然后我们就可以尝试调用 LLM 的 tools 功能"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:' const messages = [\n    {\n        "role": "user",\n        "content": "北京的天气怎么样"\n    }\n]\n\nconst result = await openai.chat.completions.create({\n    model: \'gpt-3.5-turbo\',\n    messages,\n    tools\n  });\n  console.log(result.choices[0]);\n'})}),"\n",(0,s.jsxs)(e.p,{children:["可以看到, 我们 ",(0,s.jsx)(e.code,{children:"getCurrentWeather"})," 定义是根据官方文档中的示例使用英语进行的描述, 但我们依旧可以使用中文或其他语言跟 LLM 进行沟通, 因为 LLM 其涌现的智能具有跨语言的理解能力, 那我们看一下他的返回值"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'{\n  content_filter_results: {},\n  finish_reason: "tool_calls",\n  index: 0,\n  message: {\n    content: null,\n    role: "assistant",\n    tool_calls: [\n      {\n        function: {\n          arguments: \'{\\n  "location": "Beijing",\\n  "unit": "celsius"\\n}\',\n          name: "getCurrentWeather"\n        },\n        id: "xxxxx",\n        type: "function"\n      }\n    ]\n  }\n}\n'})}),"\n",(0,s.jsx)(e.p,{children:"这里跟之前的返回值不一样, content 是空的, 也就意味着大模型并没有返回文本信息, 而是在 tool_calls 中生命了需要调用的函数内容, 参数 location 是 beijing, 而且有趣的是 它给定了另一个参数 unit 指定为摄氏度"}),"\n",(0,s.jsx)(e.p,{children:"如果我们用同样的代码, 使用英语进行提问"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:' const messages = [\n    {\n        "role": "user",\n        // "content": "北京的天气怎么样"\n        "content": "What\'s the weather like in Beijing?"\n\n    }\n]\n\nconst result = await openai.chat.completions.create({\n    // model: \'gpt-3.5-turbo\',\n    messages,\n    tools\n  });\n'})}),"\n",(0,s.jsx)(e.p,{children:"得到的结果就是"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'{\n  content_filter_results: {},\n  finish_reason: "tool_calls",\n  index: 0,\n  message: {\n    content: null,\n    role: "assistant",\n    tool_calls: [\n      {\n        function: {\n          arguments: \'{\\n"location": "Beijing"\\n}\',\n          name: "getCurrentWeather"\n        },\n        id: "xxxx",\n        type: "function"\n      }\n    ]\n  }\n}\n'})}),"\n",(0,s.jsx)(e.p,{children:"也就是, 你用中文提问他就会给第二个参数, 并指定是摄氏度, 而用英语则不会. 这也体现了 LLM 基于大量数据训练出来的涌现的智能, 在这种细节上也会有所体现. 当然我们不应该依赖于此, 可以当做对 LLM 一个有趣的观察, 因为其是一个黑盒, 有时候一些有趣的细节让我们会心一笑."}),"\n",(0,s.jsxs)(e.h2,{id:"控制-llm-调用函数的行为",children:["控制 LLM 调用函数的行为",(0,s.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#控制-llm-调用函数的行为",children:"#"})]}),"\n",(0,s.jsxs)(e.p,{children:["这里, tools 还有一个可选的参数是 ",(0,s.jsx)(e.code,{children:"tool_choice"}),", 他有几种使用方式"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"none"})," 表示, 禁止 LLM 使用任何函数, 也就是无论用户输入什么, LLM 都不会调用函数"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"auto"})," 表示, 让 LLM 自己决定是否使用函数. 也就是 LLM 的返回值可能是函数调用, 也可能正常的信息\n而最后一种, 就是指定一个函数, 让 LLM 强制使用该函数, 其类型是一个 object, 有两个属性"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"type"})," 目前只能指定为 function"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"function"}),", 其值为一个对象, 有且仅有一个 key name 为函数名称\n例如"]}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'{\n    "type": "function", \n    "function": {\n        "name": "my_function"\n    }\n}\n'})}),"\n",(0,s.jsx)(e.p,{children:"有了这个能力, 我们就具有了更细粒度去调用 LLM 的能力, 例如我们可以禁止 LLM 去调用函数"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'const messages = [\n    {\n        "role": "user",\n        "content": "北京的天气怎么样"\n    }\n]\n\nconst result = await openai.chat.completions.create({\n    model: \'gpt-3.5-turbo\',\n    messages,\n    tools,\n    tool_choice: "none"\n  });\n  console.log(result.choices[0]);\n'})}),"\n",(0,s.jsx)(e.p,{children:"其返回值是"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'{\n  content_filter_results: {\n    hate: { filtered: false, severity: "safe" },\n    self_harm: { filtered: false, severity: "safe" },\n    sexual: { filtered: false, severity: "safe" },\n    violence: { filtered: false, severity: "safe" }\n  },\n  finish_reason: "stop",\n  index: 0,\n  message: { content: "请问您需要获取北京当前的天气还是未来几天的天气预报？", role: "assistant" }\n}\n'})}),"\n",(0,s.jsx)(e.p,{children:"或者强制去调用某个函数"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'const messages = [\n    {\n        "role": "user",\n        "content": "你好"\n    }\n]\n\nconst result = await openai.chat.completions.create({\n    model: \'gpt-3.5-turbo\',\n    messages,\n    tools,\n    tool_choice: {\n        type: "function",\n        function: {\n           name: "getCurrentWeather"\n        }\n    }\n  });\n \n console.log(result.choices[0]);\n'})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'{\n  content_filter_results: {},\n  finish_reason: "stop",\n  index: 0,\n  message: {\n    content: null,\n    role: "assistant",\n    tool_calls: [\n      {\n        function: {\n          arguments: \'{\\n  "location": "上海",\\n  "unit": "celsius"\\n}\',\n          name: "getCurrentWeather"\n        },\n        id: "call_o5QJhnax6dC9e4yqHL1kLrq0",\n        type: "function"\n      }\n    ]\n  }\n}\n'})}),"\n",(0,s.jsx)(e.p,{children:"可以看到, 用户并没有提供任何跟城市和天气的信息, 但因为我们强制 LLM 去调用请求天气的函数, 所以 LLM 产生了严重的幻想问题. 至于这种强制调用有什么用, 在后面数据提取和标记一章, 大家就会看到其神奇之处."}),"\n",(0,s.jsx)(e.p,{children:"然后, 我们将 LLM 返回的调用参数, 传递给 js 中的函数中"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'const functions = {\n    "getCurrentWeather": getCurrentWeather\n  }\n\nconst functionInfo = result.choices[0].message.tool_calls[0].function\nconst functionName = functionInfo.name;\nconst functionParams = functionInfo.arguments\n\nconst functionResult = functions[functionName](functionParams);\n\nconsole.log(functionResult);\n'})}),"\n",(0,s.jsx)(e.p,{children:"在前面, 我们定义 getCurrentWeather 函数的时候, 将其参数设计为类似  React function component 一样的 object, 比较方便我们在这里调用对应的函数. 不需要了解每个函数的具体细节, 就可以直接把 argument object 塞入到对应的函数中就能得到结果"}),"\n",(0,s.jsxs)(e.h2,{id:"并发调用函数",children:["并发调用函数",(0,s.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#并发调用函数",children:"#"})]}),"\n",(0,s.jsx)(e.p,{children:"在新版的 tools 中引入了并发调用函数的特性, 可以简单的理解成之前的 function calling 每次 LLM 只会返回对一个函数的调用请求, 而 tools 可以一次返回一系列的函数调用, 来获取更多信息, 并且函数之间我们可以并行的调用来节约调用外部 API 所占用的时间.  在旧的 function calling 中, 只能让 LLM 依次返回调用请求, 来串行调用."}),"\n",(0,s.jsx)(e.p,{children:"我们这里写一个获取当前时间的 API"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'function getCurrentTime({ format = "iso" } = {}) {\n    let currentTime;\n    switch (format) {\n        case "iso":\n            currentTime = new Date().toISOString();\n            break;\n        case "locale":\n            currentTime = new Date().toLocaleString();\n            break;\n        default:\n            currentTime = new Date().toString();\n            break;\n    }\n    return currentTime;\n}\n\n'})}),"\n",(0,s.jsx)(e.p,{children:"并添加到 tools 定义中"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'const tools = [\n    {\n        type: "function",\n        function: {\n            name: "getCurrentTime",\n            description: "Get the current time in a given format",\n            parameters: {\n                type: "object",\n                properties: {\n                    format: {\n                        type: "string",\n                        enum: ["iso", "locale", "string"],\n                        description: "The format of the time, e.g. iso, locale, string",\n                    },\n                },\n                required: ["format"],\n            },\n        },\n    },\n    {\n        type: "function",\n        function: {\n          name: "getCurrentWeather",\n          description: "Get the current weather in a given location",\n          parameters: {\n            type: "object",\n            properties: {\n              location: {\n                type: "string",\n                description: "The city and state, e.g. San Francisco, CA",\n              },\n              unit: { type: "string", enum: ["celsius", "fahrenheit"] },\n            },\n            required: ["location", "unit"],\n          },\n        },\n    ]\n'})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'const messages = [\n    {\n        "role": "user",\n        "content": "请同时告诉我当前的时间, 和北京的天气"\n    }\n]\n\nconst result = await openai.chat.completions.create({\n     model: \'gpt-3.5-turbo\',\n    messages,\n    tools,\n  });\n\nconsole.log(result.choices[0]);\n'})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:' message: {\n    role: "assistant",\n    content: null,\n    tool_calls: [\n      {\n        id: "xxxx",\n        type: "function",\n        function: {\n          name: "getCurrentWeather",\n          arguments: \'{\\n  "location": "Beijing",\\n  "unit": "celsius"\\n}\'\n        }\n      },\n      {\n        id: "xxx",\n        type: "function",\n        function: {\n          name: "getCurrentTime",\n          arguments: \'{\\n  "format": "locale"\\n}\'\n        }\n      }\n    ]\n  },\n'})}),"\n",(0,s.jsx)(e.p,{children:"但这个 feature 目前十分不稳定, 如果没有精心设计过 prompt 非常难实现, 上面的示例是我跑了很多次才出现的结果, 甚至连官方示例中对多个城市的天气进行提问的示例, 在本地也很难复现"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'{ role: "user", content: "What\'s the weather like in San Francisco, Tokyo, and Paris?" },\n'})}),"\n",(0,s.jsx)(e.p,{children:"不过就像我们说的, LLM 是一个黑盒, 也在一直进步, 可能更新版本的 LLM 已经在 tools 这个方面更加灵敏了. 就目前的情况, 我们最好假设 LLM 依旧一次只能调用一个函数, 但我们可以通过设计合适的函数参数来增强这部分能力"}),"\n",(0,s.jsx)(e.p,{children:"但, LLM 在多个函数之间的决策是非常稳定的, 例如"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:' { role: "user", content: "现在几点了?" },\n    \n {\n    id: "xxx",\n    type: "function",\n    function: {\n      name: "getCurrentTime",\n      arguments: \'{\\n  "format": "locale"\\n}\'\n    }\n}\n'})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'{ role: "user", content: "北京天气如何?" },\n    \n  {\n    id: "xxx",\n    type: "function",\n    function: {\n      name: "getCurrentWeather",\n      arguments: \'{\\n  "location": "北京",\\n  "unit": "celsius"\\n}\'\n    }\n  }\n'})}),"\n",(0,s.jsxs)(e.h2,{id:"根据函数结果进行回答",children:["根据函数结果进行回答",(0,s.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#根据函数结果进行回答",children:"#"})]}),"\n",(0,s.jsx)(e.p,{children:"我们把上述所有内容联系在一起, 把函数运行结果输入给 LLM, 让 LLM 参考此进行回答."}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'const messages = [\n    { role: "user", content: "北京天气如何?" },\n]\n\nconst result = await openai.chat.completions.create({\n    model: \'gpt-3.5-turbo\',\n    messages,\n    tools\n  });\n\n'})}),"\n",(0,s.jsx)(e.p,{children:"然后, 提取结果中的函数内容, 并进行添加到 messages 中"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'messages.push(result.choices[0].message)\n\nconst functions = {\n    "getCurrentWeather": getCurrentWeather\n  }\n\nconst cell = result.choices[0].message.tool_calls[0]\nconst functionInfo = cell.function\nconst functionName = functionInfo.name;\nconst functionParams = functionInfo.arguments\nconst functionResult = functions[functionName](functionParams);\n\nmessages.push({\n  tool_call_id: cell.id,\n  role: "tool",\n  name: functionName,\n  content: functionResult,\n}); \n'})}),"\n",(0,s.jsx)(e.p,{children:"此时, message 中的结构是"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'[\n  { role: "user", content: "北京天气如何?" },\n  {\n    role: "assistant",\n    content: null,\n    tool_calls: [\n      {\n        id: "call_Kvduou0a7iW6octA20vAJFuW",\n        type: "function",\n        function: {\n          name: "getCurrentWeather",\n          arguments: \'{\\n  "location": "北京",\\n  "unit": "celsius"\\n}\'\n        }\n      }\n    ]\n  },\n  {\n    tool_call_id: "call_Kvduou0a7iW6octA20vAJFuW",\n    role: "tool",\n    name: "getCurrentWeather",\n    content: \'{"temperature":"72","unit":"fahrenheit","forecast":["sunny","windy"]}\'\n  }\n]\n'})}),"\n",(0,s.jsx)(e.p,{children:"也就是, 一条用户的提问, 一条 LLM 对函数的调用, 一条我们调用函数的结果"}),"\n",(0,s.jsx)(e.p,{children:"然后把最新的 message 传递给 LLM"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:"const response = await openai.chat.completions.create({\n  model: 'gpt-3.5-turbo',\n  messages,\n});\nconsole.log(response.choices[0].message);\n"})}),"\n",(0,s.jsx)(e.p,{children:"得到结果"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'{ role: "assistant", content: "北京的天气是晴朗和有风的，温度是22度摄氏度。" }\n'})}),"\n",(0,s.jsx)(e.p,{children:"至此, 我们完成了给 LLM 提供外部函数, 调用外部函数, 传递结果给 LLM, 让 LLM 根据此结果进行回答的完整闭环. 但你会发现, 我们为了把这个整个过程跑通需要写大量的代码, 而且我们这里只考虑了用户提问完后 LLM 一定会调用外界 API 的情况, 那如果没有调用 API 而是正常的对话呢? 是不是要加一个 if 判断?"}),"\n",(0,s.jsx)(e.p,{children:"是不是感觉距离完整的 Agent 应用要写很多东西?  是的, 在没有 Langchain 的帮助下, 我们想实现一个 LLM 自助决定行动并且根据行动结果进行下一步行动的 Agent 是非常麻烦的, 所以下一节我们会学习如何在 LangChain 中使用 tools 。。"}),"\n",(0,s.jsxs)(e.h2,{id:"小结",children:["小结",(0,s.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#小结",children:"#"})]}),"\n",(0,s.jsx)(e.p,{children:"这一章我们介绍了 OpenAI 非常强大的 tools 功能，该功能给复杂和稳定的 Agent 的使用提供了可能性。就 tools 的调用准确性和稳定性来说，openAI 依旧是第一梯队，其他 llm 在该方面做的都较差。"}),"\n",(0,s.jsx)(e.p,{children:"大家可以参考上面的代码去把玩一下，感受一下 tools 的特性，尝试把一些现有的函数接入 tools 玩一下。"})]})}function i(){let n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:e}=Object.assign({},(0,c.ah)(),n.components);return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(o,{...n})}):o(n)}let l=i;i.__RSPRESS_PAGE_META={},i.__RSPRESS_PAGE_META["%E4%BB%8E%E5%89%8D%E7%AB%AF%E5%88%B0%20AI%EF%BC%9ALangChain.js%20%E5%85%A5%E9%97%A8%E5%92%8C%E5%AE%9E%E6%88%98_online%2F17-Function%20Calling%EF%BC%9A%E4%BD%BF%E7%94%A8%20LLM%20%E5%8E%BB%E8%B0%83%E7%94%A8%E5%A4%96%E7%95%8C%20API.md"]={toc:[{text:"控制 LLM 调用函数的行为",id:"控制-llm-调用函数的行为",depth:2},{text:"并发调用函数",id:"并发调用函数",depth:2},{text:"根据函数结果进行回答",id:"根据函数结果进行回答",depth:2},{text:"小结",id:"小结",depth:2}],title:"17-Function Calling：使用 LLM 去调用外界 API",headingTitle:"17-Function Calling：使用 LLM 去调用外界 API",frontmatter:{}}}}]);